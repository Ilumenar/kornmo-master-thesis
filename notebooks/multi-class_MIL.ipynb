{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.satellite_images.storage import SentinelDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "CLASSES = ['bygg', 'rug', 'rughvete', 'hvete', 'havre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "sd = SentinelDataset('E:/MasterThesisData/Satellite_Images/small_images_all.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "       planted          area  \\\n0         bygg  94540.480524   \n1         bygg  22778.560014   \n2         bygg   5072.924216   \n3         bygg  11611.972746   \n4        havre  10203.282317   \n...        ...           ...   \n404939    None  81170.744027   \n404940    None  47871.002364   \n404941    None  22108.550434   \n404942    None  65288.461984   \n404943    None  36594.376498   \n\n                                                 geometry  \\\n0       POLYGON ((301788.79090 6608202.23000, 301789.4...   \n1       POLYGON ((301588.81297 6607862.03284, 301582.7...   \n2       POLYGON ((301544.54510 6608141.21000, 301539.9...   \n3       POLYGON ((301285.90120 6608685.32060, 301285.7...   \n4       POLYGON ((281369.42428 6687420.41295, 281369.5...   \n...                                                   ...   \n404939  POLYGON ((292000.79988 6740131.57158, 291935.5...   \n404940  POLYGON ((292036.72990 6740255.23060, 292031.3...   \n404941  POLYGON ((326429.63114 7113387.26610, 326330.0...   \n404942  POLYGON ((326242.48690 7113421.74470, 326235.8...   \n404943  POLYGON ((326167.23194 7113891.42179, 326118.7...   \n\n                         key  \n0            8119356620/2019  \n1            8119356621/2019  \n2            8119356622/2019  \n3            8119356623/2019  \n4            8125305424/2019  \n...                      ...  \n404939  999315089404939/2017  \n404940  999315089404940/2017  \n404941  999552579404941/2017  \n404942  999552579404942/2017  \n404943  999552579404943/2017  \n\n[247060 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>planted</th>\n      <th>area</th>\n      <th>geometry</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bygg</td>\n      <td>94540.480524</td>\n      <td>POLYGON ((301788.79090 6608202.23000, 301789.4...</td>\n      <td>8119356620/2019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bygg</td>\n      <td>22778.560014</td>\n      <td>POLYGON ((301588.81297 6607862.03284, 301582.7...</td>\n      <td>8119356621/2019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bygg</td>\n      <td>5072.924216</td>\n      <td>POLYGON ((301544.54510 6608141.21000, 301539.9...</td>\n      <td>8119356622/2019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bygg</td>\n      <td>11611.972746</td>\n      <td>POLYGON ((301285.90120 6608685.32060, 301285.7...</td>\n      <td>8119356623/2019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>havre</td>\n      <td>10203.282317</td>\n      <td>POLYGON ((281369.42428 6687420.41295, 281369.5...</td>\n      <td>8125305424/2019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404939</th>\n      <td>None</td>\n      <td>81170.744027</td>\n      <td>POLYGON ((292000.79988 6740131.57158, 291935.5...</td>\n      <td>999315089404939/2017</td>\n    </tr>\n    <tr>\n      <th>404940</th>\n      <td>None</td>\n      <td>47871.002364</td>\n      <td>POLYGON ((292036.72990 6740255.23060, 292031.3...</td>\n      <td>999315089404940/2017</td>\n    </tr>\n    <tr>\n      <th>404941</th>\n      <td>None</td>\n      <td>22108.550434</td>\n      <td>POLYGON ((326429.63114 7113387.26610, 326330.0...</td>\n      <td>999552579404941/2017</td>\n    </tr>\n    <tr>\n      <th>404942</th>\n      <td>None</td>\n      <td>65288.461984</td>\n      <td>POLYGON ((326242.48690 7113421.74470, 326235.8...</td>\n      <td>999552579404942/2017</td>\n    </tr>\n    <tr>\n      <th>404943</th>\n      <td>None</td>\n      <td>36594.376498</td>\n      <td>POLYGON ((326167.23194 7113891.42179, 326118.7...</td>\n      <td>999552579404943/2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>247060 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_lookup = gpd.read_file('../../kornmo-data-files/raw-data/crop-classification-data/all_data.gpkg')\n",
    "labels_lookup[\"key\"] = labels_lookup.orgnr.astype(int).astype(str) + labels_lookup.index.astype(str) + \"/\" + labels_lookup.year.astype(int).astype(str)\n",
    "labels_lookup.drop(columns=[\"year\", \"orgnr\"], inplace=True)\n",
    "\n",
    "labels_lookup.drop(labels_lookup[labels_lookup['area'] < 1500].index, inplace = True)\n",
    "labels_lookup = labels_lookup.loc[labels_lookup['planted'] != 'erter']\n",
    "labels_lookup = labels_lookup.loc[labels_lookup['planted'] != 'oljefro']\n",
    "\n",
    "# labels_lookup = labels_lookup.set_index(\"key\")\n",
    "labels_lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bygg        76231\n",
      "havre       20512\n",
      "hvete       18102\n",
      "rug           816\n",
      "rughvete      517\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "       planted          area  \\\n0         bygg  94540.480524   \n1         bygg  22778.560014   \n2         bygg   5072.924216   \n3         bygg  11611.972746   \n4        havre  10203.282317   \n...        ...           ...   \n404939    None  81170.744027   \n404940    None  47871.002364   \n404941    None  22108.550434   \n404942    None  65288.461984   \n404943    None  36594.376498   \n\n                                                 geometry  \\\n0       POLYGON ((301788.79090 6608202.23000, 301789.4...   \n1       POLYGON ((301588.81297 6607862.03284, 301582.7...   \n2       POLYGON ((301544.54510 6608141.21000, 301539.9...   \n3       POLYGON ((301285.90120 6608685.32060, 301285.7...   \n4       POLYGON ((281369.42428 6687420.41295, 281369.5...   \n...                                                   ...   \n404939  POLYGON ((292000.79988 6740131.57158, 291935.5...   \n404940  POLYGON ((292036.72990 6740255.23060, 292031.3...   \n404941  POLYGON ((326429.63114 7113387.26610, 326330.0...   \n404942  POLYGON ((326242.48690 7113421.74470, 326235.8...   \n404943  POLYGON ((326167.23194 7113891.42179, 326118.7...   \n\n                         key  \n0            8119356620/2019  \n1            8119356621/2019  \n2            8119356622/2019  \n3            8119356623/2019  \n4            8125305424/2019  \n...                      ...  \n404939  999315089404939/2017  \n404940  999315089404940/2017  \n404941  999552579404941/2017  \n404942  999552579404942/2017  \n404943  999552579404943/2017  \n\n[247060 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>planted</th>\n      <th>area</th>\n      <th>geometry</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bygg</td>\n      <td>94540.480524</td>\n      <td>POLYGON ((301788.79090 6608202.23000, 301789.4...</td>\n      <td>8119356620/2019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bygg</td>\n      <td>22778.560014</td>\n      <td>POLYGON ((301588.81297 6607862.03284, 301582.7...</td>\n      <td>8119356621/2019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bygg</td>\n      <td>5072.924216</td>\n      <td>POLYGON ((301544.54510 6608141.21000, 301539.9...</td>\n      <td>8119356622/2019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bygg</td>\n      <td>11611.972746</td>\n      <td>POLYGON ((301285.90120 6608685.32060, 301285.7...</td>\n      <td>8119356623/2019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>havre</td>\n      <td>10203.282317</td>\n      <td>POLYGON ((281369.42428 6687420.41295, 281369.5...</td>\n      <td>8125305424/2019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404939</th>\n      <td>None</td>\n      <td>81170.744027</td>\n      <td>POLYGON ((292000.79988 6740131.57158, 291935.5...</td>\n      <td>999315089404939/2017</td>\n    </tr>\n    <tr>\n      <th>404940</th>\n      <td>None</td>\n      <td>47871.002364</td>\n      <td>POLYGON ((292036.72990 6740255.23060, 292031.3...</td>\n      <td>999315089404940/2017</td>\n    </tr>\n    <tr>\n      <th>404941</th>\n      <td>None</td>\n      <td>22108.550434</td>\n      <td>POLYGON ((326429.63114 7113387.26610, 326330.0...</td>\n      <td>999552579404941/2017</td>\n    </tr>\n    <tr>\n      <th>404942</th>\n      <td>None</td>\n      <td>65288.461984</td>\n      <td>POLYGON ((326242.48690 7113421.74470, 326235.8...</td>\n      <td>999552579404942/2017</td>\n    </tr>\n    <tr>\n      <th>404943</th>\n      <td>None</td>\n      <td>36594.376498</td>\n      <td>POLYGON ((326167.23194 7113891.42179, 326118.7...</td>\n      <td>999552579404943/2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>247060 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_keep = [f\"{int(label.split('/')[1])}/{int(label.split('/')[2])}\" for label in sd.labels]\n",
    "\n",
    "print(pd.Series(list(labels_lookup['planted'])).value_counts())\n",
    "labels_lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# bygg = labels_lookup.loc[(labels_lookup['planted'].isnull()) | (labels_lookup['planted'] == 'bygg')]\n",
    "# rug = labels_lookup.loc[(labels_lookup['planted'].isnull()) | (labels_lookup['planted'] == 'rug')]\n",
    "# rughvete = labels_lookup.loc[(labels_lookup['planted'].isnull()) | (labels_lookup['planted'] == 'rughvete')]\n",
    "# hvete = labels_lookup.loc[(labels_lookup['planted'].isnull()) | (labels_lookup['planted'] == 'hvete')]\n",
    "# havre = labels_lookup.loc[(labels_lookup['planted'].isnull()) | (labels_lookup['planted'] == 'havre')]\n",
    "\n",
    "# print(f'Bygg {bygg.shape}')\n",
    "# print(f'Rug {rug.shape}')\n",
    "# print(f'Rughvete {rughvete.shape}')\n",
    "# print(f'Hvete {hvete.shape}')\n",
    "# print(f'Havre {havre.shape}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "BAG_COUNT = 3500\n",
    "VAL_BAG_COUNT = 500\n",
    "BAG_SIZE = 7\n",
    "PLOT_SIZE = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178390/178390 [00:00<00:00, 292467.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 124873\n",
      "x_val: 53517\n",
      "y_train: 124873\n",
      "y_val: 53517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = labels_lookup['planted']\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i, label in tqdm(enumerate(labels_to_keep), total=len(labels_to_keep)):\n",
    "    data_x.append(label)\n",
    "    data_y.append(labels.iloc[i])\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.3, random_state=42)\n",
    "print(f'x_train: {len(x_train)}')\n",
    "print(f'x_val: {len(x_val)}')\n",
    "print(f'y_train: {len(y_train)}')\n",
    "print(f'y_val: {len(y_val)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bygg\n",
      "811555762115601/2018\n",
      "811555762115601/2018\n"
     ]
    }
   ],
   "source": [
    "print(data_y[0])\n",
    "print(data_x[0])\n",
    "print(labels_to_keep[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating bag for bygg: 100%|██████████| 3500/3500 [00:07<00:00, 480.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive bags: 3432\n",
      "Negative bags: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating bag for bygg: 100%|██████████| 500/500 [00:00<00:00, 1168.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive bags: 492\n",
      "Negative bags: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n",
    "    bags = []\n",
    "    bag_labels = []\n",
    "\n",
    "    # input_data = np.divide(input_data, 255.0)\n",
    "\n",
    "    count = 0\n",
    "    for _ in tqdm(range(bag_count), desc=f'Creating bag for {positive_class}'):\n",
    "        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n",
    "        instances_data = input_data[index]\n",
    "        instances_labels = input_labels[index]\n",
    "\n",
    "        bag_label = 0\n",
    "\n",
    "        if positive_class in instances_labels:\n",
    "            bag_label = 1\n",
    "            count += 1\n",
    "\n",
    "        bags.append(instances_data)\n",
    "        bag_labels.append(np.array([bag_label]))\n",
    "\n",
    "    print(f\"Positive bags: {count}\")\n",
    "    print(f\"Negative bags: {bag_count - count}\")\n",
    "    # return list(np.swapaxes(bags, 0, 1)), np.array(bag_labels)\n",
    "    return np.array(bags), np.array(bag_labels)\n",
    "\n",
    "\n",
    "train_data, train_labels = create_bags(np.array(x_train), np.array(y_train), 'bygg', BAG_COUNT, BAG_SIZE)\n",
    "\n",
    "val_data, val_labels = create_bags(np.array(x_val), np.array(y_val), 'bygg', VAL_BAG_COUNT, BAG_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bag class label is positive\n",
      "Bag number: 0\n",
      "969198843/2017\n",
      "982804264/2018\n",
      "985257256/2018\n",
      "990844011/2019\n",
      "969089572/2019\n",
      "977093880/2017\n",
      "992725613/2019\n",
      "976744314/2019\n",
      "983064590/2019\n",
      "969930404/2018\n",
      "Bag number: 1\n",
      "987668601/2018\n",
      "969378612/2019\n",
      "820802322/2018\n",
      "985878684/2018\n",
      "916463499/2018\n",
      "969091879/2017\n",
      "986639748/2018\n",
      "969247682/2019\n",
      "997736494/2017\n",
      "969098326/2018\n",
      "Bag number: 2\n",
      "923088652/2019\n",
      "969092670/2018\n",
      "965208739/2019\n",
      "977163048/2019\n",
      "887932522/2018\n",
      "991853812/2017\n",
      "971156694/2019\n",
      "987615931/2017\n",
      "970569065/2018\n",
      "980388565/2018\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 97 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17424/1872254316.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;31m# Plot some of validation data bags per class.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"positive\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m \u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"negative\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17424/1872254316.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(data, labels, bag_class, predictions, attention_weights)\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m             \u001B[0mbags\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mPLOT_SIZE\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 97 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "def plot(data, labels, bag_class, predictions=None, attention_weights=None):\n",
    "\n",
    "    labels = np.array(labels).reshape(-1)\n",
    "\n",
    "    if bag_class == \"positive\":\n",
    "        if predictions is not None:\n",
    "            labels = np.where(predictions.argmax(1) == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "        else:\n",
    "            labels = np.where(labels == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "    elif bag_class == \"negative\":\n",
    "        if predictions is not None:\n",
    "            labels = np.where(predictions.argmax(1) == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "        else:\n",
    "            labels = np.where(labels == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "\n",
    "    else:\n",
    "        print(f\"There is no class {bag_class}\")\n",
    "        return\n",
    "\n",
    "    print(f\"The bag class label is {bag_class}\")\n",
    "    for i in range(PLOT_SIZE):\n",
    "        # figure = plt.figure(figsize=(8, 8))\n",
    "        print(f\"Bag number: {labels[i]}\")\n",
    "        for j in range(BAG_SIZE):\n",
    "            # image = bags[j][i]\n",
    "            # figure.add_subplot(1, BAG_SIZE, j + 1)\n",
    "            # plt.grid(False)\n",
    "            # if attention_weights is not None:\n",
    "            #     plt.title(np.around(attention_weights[labels[i]][j], 2))\n",
    "            # plt.imshow(image)\n",
    "            print(bags[j][i])\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "# Plot some of validation data bags per class.\n",
    "plot(train_data, train_labels, \"positive\")\n",
    "plot(train_data, train_labels, \"negative\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 116.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 132.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 133.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 140.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 157.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 134.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 129.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 30, 16, 16, 12)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_generator():\n",
    "    for i, row in enumerate(train_data):\n",
    "        all_imgs = []\n",
    "        for key in tqdm(row, total=len(row)):\n",
    "            imgs = sd.get_images(key.split('/')[0], key.split('/')[1])\n",
    "            all_imgs.append(imgs)\n",
    "\n",
    "        yield all_imgs, train_labels[i]\n",
    "\n",
    "\n",
    "def val_generator():\n",
    "    for i, row in enumerate(val_data):\n",
    "        all_imgs = []\n",
    "        for key in tqdm(row, total=len(row)):\n",
    "\n",
    "            imgs = sd.get_images(int(key.split('/')[0]), int(key.split('/')[1]))\n",
    "            all_imgs.append(imgs)\n",
    "        print(np.array(all_imgs[0]).shape)\n",
    "\n",
    "        yield all_imgs, val_labels[i]\n",
    "\n",
    "i = 0\n",
    "for test in train_generator():\n",
    "    print(np.array(test[0]).shape)\n",
    "    print(test[1])\n",
    "    if i > 5:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_generator,\n",
    "    output_types=(tf.dtypes.float64, tf.dtypes.int64),\n",
    "    output_shapes=((7, 30, 16, 16, 12), 1)\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val_generator,\n",
    "    output_types=(tf.dtypes.float64, tf.dtypes.int64),\n",
    "    output_shapes=((7, 30, 16, 16, 12), 1)\n",
    ")\n",
    "\n",
    "# print(train_dataset)\n",
    "# print(tuple(train_dataset))\n",
    "# for test in train_generator():\n",
    "#     print(np.array(test[0]).shape)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 7, 30, 16, 16, 12), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))>"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.batch(2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "class MILAttentionLayer(layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        weight_params_dim,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        use_gated=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.weight_params_dim = weight_params_dim\n",
    "        self.use_gated = use_gated\n",
    "\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "        self.v_init = self.kernel_initializer\n",
    "        self.w_init = self.kernel_initializer\n",
    "        self.u_init = self.kernel_initializer\n",
    "\n",
    "        self.v_regularizer = self.kernel_regularizer\n",
    "        self.w_regularizer = self.kernel_regularizer\n",
    "        self.u_regularizer = self.kernel_regularizer\n",
    "\n",
    "\n",
    "        # Input shape.\n",
    "        # List of 2D tensors with shape: (batch_size, input_dim).\n",
    "        input_dim = 16\n",
    "\n",
    "        self.v_weight_params = self.add_weight(\n",
    "            shape=(input_dim, self.weight_params_dim),\n",
    "            initializer=self.v_init,\n",
    "            name=\"v\",\n",
    "            regularizer=self.v_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_weight_params = self.add_weight(\n",
    "            shape=(self.weight_params_dim, 1),\n",
    "            initializer=self.w_init,\n",
    "            name=\"w\",\n",
    "            regularizer=self.w_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        if self.use_gated:\n",
    "            self.u_weight_params = self.add_weight(\n",
    "                shape=(input_dim, self.weight_params_dim),\n",
    "                initializer=self.u_init,\n",
    "                name=\"u\",\n",
    "                regularizer=self.u_regularizer,\n",
    "                trainable=True,\n",
    "            )\n",
    "        else:\n",
    "            self.u_weight_params = None\n",
    "\n",
    "        self.input_built = True\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "\n",
    "        # Assigning variables from the number of inputs.\n",
    "        instances = [self.compute_attention_scores(instance) for instance in inputs]\n",
    "\n",
    "        # Apply softmax over instances such that the output summation is equal to 1.\n",
    "        alpha = tf.math.softmax(instances, axis=0)\n",
    "\n",
    "        return [alpha[i] for i in range(alpha.shape[0])]\n",
    "\n",
    "    def compute_attention_scores(self, instance):\n",
    "\n",
    "        # Reserve in-case \"gated mechanism\" used.\n",
    "        original_instance = instance\n",
    "\n",
    "        # tanh(v*h_k^T)\n",
    "        instance = tf.math.tanh(tf.tensordot(instance, self.v_weight_params, axes=1))\n",
    "\n",
    "        # for learning non-linear relations efficiently.\n",
    "        if self.use_gated:\n",
    "\n",
    "            instance = instance * tf.math.sigmoid(\n",
    "                tf.tensordot(original_instance, self.u_weight_params, axes=1)\n",
    "            )\n",
    "\n",
    "        # w^T*(tanh(v*h_k^T)) / w^T*(tanh(v*h_k^T)*sigmoid(u*h_k^T))\n",
    "        return tf.tensordot(instance, self.w_weight_params, axes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def create_model(instance_shape):\n",
    "\n",
    "    # Extract features from inputs.\n",
    "    inputs, embeddings = [], []\n",
    "    shared_dense_layer_1 = layers.Dense(128, activation=\"relu\")\n",
    "    shared_dense_layer_2 = layers.Dense(64, activation=\"relu\")\n",
    "    for _ in range(BAG_SIZE):\n",
    "        inp = layers.Input(instance_shape)\n",
    "        flatten = layers.Flatten()(inp)\n",
    "        dense_1 = shared_dense_layer_1(flatten)\n",
    "        dense_2 = shared_dense_layer_2(dense_1)\n",
    "        inputs.append(inp)\n",
    "        embeddings.append(dense_2)\n",
    "\n",
    "    # Invoke the attention layer.\n",
    "    alpha = MILAttentionLayer(weight_params_dim=256, kernel_regularizer=keras.regularizers.l2(0.01), use_gated=True, name=\"alpha\")(embeddings)\n",
    "\n",
    "    # Multiply attention weights with the input layers.\n",
    "    multiply_layers = [\n",
    "        layers.multiply([alpha[i], embeddings[i]]) for i in range(len(alpha))\n",
    "    ]\n",
    "\n",
    "    # Concatenate layers.\n",
    "    concat = layers.concatenate(multiply_layers, axis=1)\n",
    "\n",
    "    # Classification output node.\n",
    "    output = layers.Dense(2, activation=\"softmax\")(concat)\n",
    "\n",
    "    return keras.Model(inputs, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def compute_class_weights(labels):\n",
    "\n",
    "    # Count number of postive and negative bags.\n",
    "    negative_count = len(np.where(labels == 0)[0])\n",
    "    positive_count = len(np.where(labels == 1)[0])\n",
    "    total_count = negative_count + positive_count\n",
    "\n",
    "    # Build class weight dictionary.\n",
    "    return {\n",
    "        0: (1 / negative_count) * (total_count / 2),\n",
    "        1: (1 / positive_count) * (total_count / 2),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_147), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_148), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_149), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_150), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_151), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_152), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_153), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_154), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_155), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_156), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_157), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_158), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_159), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_160), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_161), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_162), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_163), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_164), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_165), but are not present in its tracked objects:   <tf.Variable 'v:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_166), but are not present in its tracked objects:   <tf.Variable 'u:0' shape=(16, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tensordot_167), but are not present in its tracked objects:   <tf.Variable 'w:0' shape=(256, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_50 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_51 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_52 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_53 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_55 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 30, 16, 16,  0           []                               \n",
      "                                 12)]                                                             \n",
      "                                                                                                  \n",
      " flatten_49 (Flatten)           (None, 92160)        0           ['input_50[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_50 (Flatten)           (None, 92160)        0           ['input_51[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_51 (Flatten)           (None, 92160)        0           ['input_52[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_52 (Flatten)           (None, 92160)        0           ['input_53[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_53 (Flatten)           (None, 92160)        0           ['input_54[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_54 (Flatten)           (None, 92160)        0           ['input_55[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_55 (Flatten)           (None, 92160)        0           ['input_56[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 128)          11796608    ['flatten_49[0][0]',             \n",
      "                                                                  'flatten_50[0][0]',             \n",
      "                                                                  'flatten_51[0][0]',             \n",
      "                                                                  'flatten_52[0][0]',             \n",
      "                                                                  'flatten_53[0][0]',             \n",
      "                                                                  'flatten_54[0][0]',             \n",
      "                                                                  'flatten_55[0][0]']             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 64)           8256        ['dense_21[0][0]',               \n",
      "                                                                  'dense_21[1][0]',               \n",
      "                                                                  'dense_21[2][0]',               \n",
      "                                                                  'dense_21[3][0]',               \n",
      "                                                                  'dense_21[4][0]',               \n",
      "                                                                  'dense_21[5][0]',               \n",
      "                                                                  'dense_21[6][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_147 (TFOpLambda)  (None, 256)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_148 (TFOpLambda)  (None, 256)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_150 (TFOpLambda)  (None, 256)          0           ['dense_22[1][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_151 (TFOpLambda)  (None, 256)          0           ['dense_22[1][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_153 (TFOpLambda)  (None, 256)          0           ['dense_22[2][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_154 (TFOpLambda)  (None, 256)          0           ['dense_22[2][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_156 (TFOpLambda)  (None, 256)          0           ['dense_22[3][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_157 (TFOpLambda)  (None, 256)          0           ['dense_22[3][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_159 (TFOpLambda)  (None, 256)          0           ['dense_22[4][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_160 (TFOpLambda)  (None, 256)          0           ['dense_22[4][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_162 (TFOpLambda)  (None, 256)          0           ['dense_22[5][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_163 (TFOpLambda)  (None, 256)          0           ['dense_22[5][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_165 (TFOpLambda)  (None, 256)          0           ['dense_22[6][0]']               \n",
      "                                                                                                  \n",
      " tf.tensordot_166 (TFOpLambda)  (None, 256)          0           ['dense_22[6][0]']               \n",
      "                                                                                                  \n",
      " tf.math.tanh_49 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_147[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_49 (TFOpLambda  (None, 256)         0           ['tf.tensordot_148[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_50 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_150[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_50 (TFOpLambda  (None, 256)         0           ['tf.tensordot_151[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_51 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_153[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_51 (TFOpLambda  (None, 256)         0           ['tf.tensordot_154[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_52 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_156[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_52 (TFOpLambda  (None, 256)         0           ['tf.tensordot_157[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_53 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_159[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_53 (TFOpLambda  (None, 256)         0           ['tf.tensordot_160[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_54 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_162[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_54 (TFOpLambda  (None, 256)         0           ['tf.tensordot_163[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.tanh_55 (TFOpLambda)   (None, 256)          0           ['tf.tensordot_165[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_55 (TFOpLambda  (None, 256)         0           ['tf.tensordot_166[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_49 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_49[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_49[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_50 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_50[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_50[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_51 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_51[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_51[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_52 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_52[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_52[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_53 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_53[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_53[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_54 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_54[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_54[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_55 (TFOpLambd  (None, 256)         0           ['tf.math.tanh_55[0][0]',        \n",
      " a)                                                               'tf.math.sigmoid_55[0][0]']     \n",
      "                                                                                                  \n",
      " tf.tensordot_149 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_49[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_152 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_50[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_155 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_51[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_158 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_52[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_161 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_53[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_164 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_54[0][0]']    \n",
      "                                                                                                  \n",
      " tf.tensordot_167 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_55[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.softmax_7 (TFOpLambda)   (7, None, 1)         0           ['tf.tensordot_149[0][0]',       \n",
      "                                                                  'tf.tensordot_152[0][0]',       \n",
      "                                                                  'tf.tensordot_155[0][0]',       \n",
      "                                                                  'tf.tensordot_158[0][0]',       \n",
      "                                                                  'tf.tensordot_161[0][0]',       \n",
      "                                                                  'tf.tensordot_164[0][0]',       \n",
      "                                                                  'tf.tensordot_167[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_49 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_50 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_51 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_52 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_53 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_54 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_55 (S  (None, 1)           0           ['tf.nn.softmax_7[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " multiply_49 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_49[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_50 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_50[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[1][0]']               \n",
      "                                                                                                  \n",
      " multiply_51 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_51[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[2][0]']               \n",
      "                                                                                                  \n",
      " multiply_52 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_52[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[3][0]']               \n",
      "                                                                                                  \n",
      " multiply_53 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_53[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[4][0]']               \n",
      "                                                                                                  \n",
      " multiply_54 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_54[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[5][0]']               \n",
      "                                                                                                  \n",
      " multiply_55 (Multiply)         (None, 64)           0           ['tf.__operators__.getitem_55[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'dense_22[6][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 448)          0           ['multiply_49[0][0]',            \n",
      "                                                                  'multiply_50[0][0]',            \n",
      "                                                                  'multiply_51[0][0]',            \n",
      "                                                                  'multiply_52[0][0]',            \n",
      "                                                                  'multiply_53[0][0]',            \n",
      "                                                                  'multiply_54[0][0]',            \n",
      "                                                                  'multiply_55[0][0]']            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 2)            898         ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,805,762\n",
      "Trainable params: 11,805,762\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_7\" expects 7 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(7, 30, 16, 16, 12) dtype=float64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17424/953118840.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m \u001B[0mtrained_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17424/953118840.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(train_data, train_labels, val_data, val_labels, model)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"adam\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"sparse_categorical_crossentropy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"accuracy\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m     model.fit(\n\u001B[0m\u001B[0;32m     21\u001B[0m         \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_7\" expects 7 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(7, 30, 16, 16, 12) dtype=float64>]\n"
     ]
    }
   ],
   "source": [
    "def train(train_data, train_labels, val_data, val_labels, model):\n",
    "\n",
    "    # Take the file name from the wrapper.\n",
    "    file_path = \"/tmp/best_model_weights.h5\"\n",
    "\n",
    "    # Initialize model checkpoint callback.\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        file_path,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, mode=\"min\")\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=50,\n",
    "        class_weight=compute_class_weights(train_labels),\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "instance_shape = train_data[0][0].shape\n",
    "print(instance_shape)\n",
    "model = create_model((30, 16, 16, 12))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "trained_model = train(train_data, train_labels, val_data, val_labels, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}