{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from kornmo import KornmoDataset\n",
    "from frostdataset import FrostDataset\n",
    "from visualize import plot\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kornmo_utils as ku\n",
    "from visualize import plot_history\n",
    "from keras.models import load_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_by_years(years, data):\n",
    "    return data[data['year'].isin(years)]\n",
    "\n",
    "def get_interpolated_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/nn_interpolated/{weather_feature}/{weather_feature}_interpolated_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    # Drop columns containing 'Unnamed'\n",
    "    data.drop(columns=[col for col in data.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year', 'longitude', 'latitude', 'elevation']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_proximity_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/by_proximity/{weather_feature}/{weather_feature}_by_proximity_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.drop(columns=['ws_id'], inplace=True)\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_soilquality_data():\n",
    "    data = pd.read_csv(f'../../kornmo-data-files/raw-data/farm-information/farmers-with-coordinates-and-soil_quality.csv')\n",
    "    data.drop(columns=['Unnamed: 0', 'latitude', 'longitude', 'elevation'], inplace=True)\n",
    "    return_data = ku.normalize(data.drop(columns=['orgnr']))\n",
    "    return_data.insert(0, 'orgnr', data['orgnr'])\n",
    "    return return_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frost = FrostDataset()\n",
    "kornmo = KornmoDataset()\n",
    "\n",
    "years = [2017, 2018, 2019]\n",
    "\n",
    "# Grants and deliveries\n",
    "data = kornmo.get_deliveries().pipe(ku.split_farmers_on_type)\n",
    "data = filter_by_years(years, data)\n",
    "data\n",
    "#45314 x 15\n",
    "#60462 x 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Temperature and Precipitation\n",
    "temp_and_precip_data = frost.get_as_aggregated(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sunlight_data = get_interpolated_data(years, 'sunlight')\n",
    "daydegree5_data = get_interpolated_data(years, 'daydegree5').drop(columns=['longitude', 'latitude', 'elevation'])\n",
    "ground_data = get_proximity_data(years, 'ground')\n",
    "weather_data = temp_and_precip_data.merge(sunlight_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(daydegree5_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(ground_data, how='left', on=['orgnr', 'year'])\n",
    "\n",
    "print(f\"Merged {temp_and_precip_data.shape[1]} features of temp and precip data, {sunlight_data.shape[1]} features of sunlight data, {daydegree5_data.shape[1]} features of daydegree data, {ground_data.shape[1]} features of ground data to a total of {weather_data.shape[1]} features\")\n",
    "\n",
    "data = data.merge(weather_data, how='left', on=['year', 'orgnr'])\n",
    "data = filter_by_years(years, data)\n",
    "data\n",
    "# 49044 x 1523\n",
    "# 65277 x 1523"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soilquality_data = get_soilquality_data()\n",
    "data = data.merge(soilquality_data, on=['orgnr'])\n",
    "data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Legacy grants\n",
    "historical_data = ku.get_historical_production(kornmo, data.year.unique(), 4)\n",
    "data = data.merge(historical_data, on=['orgnr', 'year'])\n",
    "data = filter_by_years(years, data)\n",
    "data\n",
    "# 47191 x 1541\n",
    "# 62309 x 1541"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "\n",
    "data['y'] = data['levert'] / data['areal']\n",
    "data.drop('levert', axis=1, inplace=True)\n",
    "\n",
    "data['y'] = ku.normalize(data['y'], 0, 1000)\n",
    "data['areal'] = ku.normalize(data['areal'])\n",
    "data['fulldyrket'] = ku.normalize(data['fulldyrket'])\n",
    "data['overflatedyrket'] = ku.normalize(data['overflatedyrket'])\n",
    "data['tilskudd_dyr'] = ku.normalize(data['tilskudd_dyr'])\n",
    "data['growth_start_day'] = ku.normalize(data['growth_start_day'])\n",
    "data['elevation'] = ku.normalize(data['elevation'])\n",
    "data['latitude'] = ku.normalize(data['latitude'])\n",
    "data['longitude'] = ku.normalize(data['longitude'])\n",
    "\n",
    "y_column = ['y']\n",
    "remove_from_training = ['orgnr', 'kommunenr', 'gaardsnummer', 'bruksnummer', 'festenummer', 'year'] + y_column\n",
    "\n",
    "data\n",
    "# 41383 x 1541"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, val = train_test_split(shuffle(data), test_size=0.2)\n",
    "val, test = train_test_split(val, test_size=0.2)\n",
    "\n",
    "train_x = train.drop(remove_from_training, axis=1).to_numpy()\n",
    "train_y = train[y_column].to_numpy()\n",
    "\n",
    "val_x = val.drop(remove_from_training, axis=1).to_numpy()\n",
    "val_y = val[y_column].to_numpy()\n",
    "\n",
    "print(f'Training dataset x: {train_x.shape}')\n",
    "print(f'Training dataset y: {train_y.shape}')\n",
    "print(f'Validation dataset x: {val_x.shape}')\n",
    "print(f'Validation dataset y : {val_y.shape}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kornmo.dense_model import train_simple_dense\n",
    "logs_name = 'more_features_with_soil_quality'\n",
    "\n",
    "model, history = train_simple_dense(train_x, train_y, val_x, val_y)\n",
    "plot_history(history.history, save_file=f\"logs/dnn_loss_{logs_name}.svg\")\n",
    "plot(model, val_x, val_y)\n",
    "\n",
    "\n",
    "print(\"Saving model and history object\")\n",
    "\n",
    "pd.DataFrame(history.history).to_csv(f'logs/history_{logs_name}.csv')\n",
    "model.save(f\"logs/dnn_model_{logs_name}.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = pd.read_csv(f'logs/history_{logs_name}.csv')\n",
    "plot_history(history, save_file=f\"logs/dnn_loss_{logs_name}.svg\")\n",
    "\n",
    "model = load_model(f\"logs/dnn_model_{logs_name}.keras\")\n",
    "plot(model, val_x, val_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}