{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from kornmo import KornmoDataset\n",
    "from geodata import get_farmer_elevation\n",
    "from kornmo import kornmo_utils as ku\n",
    "from frostdataset import FrostDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def filter_by_years(years, data):\n",
    "    return data[data['year'].isin(years)]\n",
    "\n",
    "def get_interpolated_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'data/frost/nn_interpolated/{weather_feature}/{weather_feature}_interpolated_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    # Drop columns containing 'Unnamed'\n",
    "    data.drop(columns=[col for col in data.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year', 'longitude', 'latitude', 'elevation']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_proximity_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'data/frost/by_proximity/{weather_feature}/{weather_feature}_by_proximity_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.drop(columns=['ws_id'], inplace=True)\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deliveries...\n",
      "Number of deliveries loaded: 78290\n"
     ]
    },
    {
     "data": {
      "text/plain": "                year      orgnr  kommunenr  gaardsnummer  bruksnummer  \\\nkey                                                                     \n811555762/2017  2017  811555762       1653            24            2   \n811580082/2017  2017  811580082       1124            25            5   \n811675792/2017  2017  811675792        709          2023           12   \n811675792/2017  2017  811675792        709          2023           12   \n811935662/2017  2017  811935662        125           207            1   \n...              ...        ...        ...           ...          ...   \n999659209/2019  2019  999659209        811            31           64   \n999662730/2019  2019  999662730        715           247            1   \n999662730/2019  2019  999662730        715           247            1   \n999665462/2019  2019  999665462        229            69            1   \n999666248/2019  2019  999666248        226            52           10   \n\n                festenummer  fulldyrket  overflatedyrket  tilskudd_dyr  \\\nkey                                                                      \n811555762/2017            0    0.007674              0.0      0.000000   \n811580082/2017            0    0.117186              0.0      0.344044   \n811675792/2017            0    0.015028              0.0      0.000000   \n811675792/2017            0    0.015028              0.0      0.000000   \n811935662/2017            0    0.015188              0.0      0.000000   \n...                     ...         ...              ...           ...   \n999659209/2019            0    0.014548              0.0      0.000000   \n999662730/2019            0    0.046523              0.0      0.000000   \n999662730/2019            0    0.046523              0.0      0.000000   \n999665462/2019            0    0.023981              0.0      0.047922   \n999666248/2019            0    0.023821              0.0      0.000000   \n\n                levert     areal  bygg  havre  hvete  rug_og_rughvete  \\\nkey                                                                     \n811555762/2017   17067  0.017179   1.0    0.0    0.0              0.0   \n811580082/2017   81204  0.064195   1.0    0.0    0.0              0.0   \n811675792/2017   10902  0.020494   1.0    0.0    0.0              0.0   \n811675792/2017    2335  0.003918   0.0    0.0    1.0              0.0   \n811935662/2017   33166  0.031344   0.0    0.0    1.0              0.0   \n...                ...       ...   ...    ...    ...              ...   \n999659209/2019   13426  0.017782   1.0    0.0    0.0              0.0   \n999662730/2019   86888  0.052743   0.0    1.0    0.0              0.0   \n999662730/2019   44841  0.035564   0.0    0.0    1.0              0.0   \n999665462/2019   21835  0.015371   0.0    1.0    0.0              0.0   \n999666248/2019   95683  0.047619   1.0    0.0    0.0              0.0   \n\n                     lat  elevation     yield  \nkey                                            \n811555762/2017  0.959116   0.051198  0.289271  \n811580082/2017  0.891830   0.024510  0.377693  \n811675792/2017  0.896483   0.014706  0.155743  \n811675792/2017  0.896483   0.014706  0.155667  \n811935662/2017  0.907412   0.073529  0.312887  \n...                  ...        ...       ...  \n999659209/2019  0.898225   0.068627  0.220098  \n999662730/2019  0.902149   0.093137  0.490893  \n999662730/2019  0.902149   0.093137  0.373675  \n999665462/2019  0.905165   0.142157  0.411981  \n999666248/2019  0.909951   0.132353  0.598019  \n\n[45327 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>orgnr</th>\n      <th>kommunenr</th>\n      <th>gaardsnummer</th>\n      <th>bruksnummer</th>\n      <th>festenummer</th>\n      <th>fulldyrket</th>\n      <th>overflatedyrket</th>\n      <th>tilskudd_dyr</th>\n      <th>levert</th>\n      <th>areal</th>\n      <th>bygg</th>\n      <th>havre</th>\n      <th>hvete</th>\n      <th>rug_og_rughvete</th>\n      <th>lat</th>\n      <th>elevation</th>\n      <th>yield</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>2017</td>\n      <td>811555762</td>\n      <td>1653</td>\n      <td>24</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.007674</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>17067</td>\n      <td>0.017179</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.959116</td>\n      <td>0.051198</td>\n      <td>0.289271</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2017</td>\n      <td>811580082</td>\n      <td>1124</td>\n      <td>25</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.117186</td>\n      <td>0.0</td>\n      <td>0.344044</td>\n      <td>81204</td>\n      <td>0.064195</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.891830</td>\n      <td>0.024510</td>\n      <td>0.377693</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.015028</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>10902</td>\n      <td>0.020494</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155743</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.015028</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2335</td>\n      <td>0.003918</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155667</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>2017</td>\n      <td>811935662</td>\n      <td>125</td>\n      <td>207</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.015188</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>33166</td>\n      <td>0.031344</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.907412</td>\n      <td>0.073529</td>\n      <td>0.312887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999659209/2019</th>\n      <td>2019</td>\n      <td>999659209</td>\n      <td>811</td>\n      <td>31</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0.014548</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>13426</td>\n      <td>0.017782</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.898225</td>\n      <td>0.068627</td>\n      <td>0.220098</td>\n    </tr>\n    <tr>\n      <th>999662730/2019</th>\n      <td>2019</td>\n      <td>999662730</td>\n      <td>715</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.046523</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>86888</td>\n      <td>0.052743</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.490893</td>\n    </tr>\n    <tr>\n      <th>999662730/2019</th>\n      <td>2019</td>\n      <td>999662730</td>\n      <td>715</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.046523</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>44841</td>\n      <td>0.035564</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.373675</td>\n    </tr>\n    <tr>\n      <th>999665462/2019</th>\n      <td>2019</td>\n      <td>999665462</td>\n      <td>229</td>\n      <td>69</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.023981</td>\n      <td>0.0</td>\n      <td>0.047922</td>\n      <td>21835</td>\n      <td>0.015371</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.905165</td>\n      <td>0.142157</td>\n      <td>0.411981</td>\n    </tr>\n    <tr>\n      <th>999666248/2019</th>\n      <td>2019</td>\n      <td>999666248</td>\n      <td>226</td>\n      <td>52</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.023821</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>95683</td>\n      <td>0.047619</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.909951</td>\n      <td>0.132353</td>\n      <td>0.598019</td>\n    </tr>\n  </tbody>\n</table>\n<p>45327 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [2017, 2018, 2019]\n",
    "frost = FrostDataset()\n",
    "kornmo = KornmoDataset()\n",
    "deliveries = kornmo.get_deliveries().pipe(ku.split_farmers_on_type)\n",
    "\n",
    "elevation_data = get_farmer_elevation()\n",
    "deliveries = deliveries.merge(elevation_data, on=['orgnr'], how='left').fillna(0)\n",
    "\n",
    "deliveries[\"yield\"] = ku.normalize(deliveries[\"levert\"]/deliveries[\"areal\"], 0, 1000)\n",
    "deliveries[\"areal\"] = ku.normalize(deliveries[\"areal\"])\n",
    "deliveries['fulldyrket'] = ku.normalize(deliveries['fulldyrket'])\n",
    "deliveries['overflatedyrket'] = ku.normalize(deliveries['overflatedyrket'])\n",
    "deliveries['tilskudd_dyr'] = ku.normalize(deliveries['tilskudd_dyr'])\n",
    "deliveries['lat'] = ku.normalize(deliveries['lat'])\n",
    "deliveries['elevation'] = ku.normalize(deliveries['elevation'])\n",
    "\n",
    "deliveries[\"key\"] = deliveries.orgnr.astype(str) + \"/\" + deliveries.year.astype(str)\n",
    "deliveries = deliveries.set_index(\"key\")\n",
    "deliveries = filter_by_years(years, deliveries)\n",
    "\n",
    "deliveries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical grants data...\n",
      "Historical data loaded for years 2013 to 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\kornmo_utils.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(history_data, ignore_index=True)\n",
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\kornmo_utils.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(history_data, ignore_index=True)\n",
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\kornmo_utils.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(history_data, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                bygg_sum_0  hvete_sum_0  havre_sum_0  rug_og_rughvete_sum_0  \\\nkey                                                                           \n811555762/2017      1.3687       0.0000       0.0000                    0.0   \n811580082/2017      2.9200       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       0.0000       0.0000                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7688       0.4413       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2019      0.0000      21.5508       4.7821                    0.0   \n999659209/2019      0.0000       2.2603       0.0000                    0.0   \n999662730/2019      0.0000       5.1119       9.7433                    0.0   \n999665462/2019      0.0000       0.0000       0.0000                    0.0   \n999666248/2019      9.5523       0.0000       0.0000                    0.0   \n\n                bygg_sum_1  hvete_sum_1  havre_sum_1  rug_og_rughvete_sum_1  \\\nkey                                                                           \n811555762/2017      2.2050       0.0000       0.0000                    0.0   \n811580082/2017      4.7596       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       2.8870       0.6015                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      3.3676       0.0000       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2019     14.6406       0.0000       4.8990                    0.0   \n999659209/2019      1.8102       0.0000       0.0000                    0.0   \n999662730/2019      0.0000       2.9122      10.4515                    0.0   \n999665462/2019      0.0000       0.0000       0.0000                    0.0   \n999666248/2019      0.0000       0.0000       9.8484                    0.0   \n\n                bygg_sum_2  hvete_sum_2  havre_sum_2  rug_og_rughvete_sum_2  \\\nkey                                                                           \n811555762/2017      2.0620       0.0000       0.0000                    0.0   \n811580082/2017      6.4999       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       1.4844       0.2770                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7060       1.4768       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2019      9.4914      33.1335       5.0059                    0.0   \n999659209/2019      0.0000       1.1576       0.0000                    0.0   \n999662730/2019      0.0000       4.7917       8.2873                    0.0   \n999665462/2019      0.0000       0.0000       2.1122                    0.0   \n999666248/2019      0.0000       0.0000       8.5110                    0.0   \n\n                bygg_sum_3  hvete_sum_3  havre_sum_3  rug_og_rughvete_sum_3  \nkey                                                                          \n811555762/2017      2.2445       0.0000       0.0000                    0.0  \n811580082/2017     11.7227       0.0000       0.0000                    0.0  \n811675792/2017      0.0000       2.2717       0.4869                    0.0  \n811935662/2017      1.0643       2.5620       0.0000                    0.0  \n812075322/2017      2.2838       1.0750       0.0000                    0.0  \n...                    ...          ...          ...                    ...  \n999640001/2019      8.4269       6.3109       0.0000                    0.0  \n999659209/2019      0.0000       0.0000       1.5396                    0.0  \n999662730/2019      0.0000       1.8919       5.8078                    0.0  \n999665462/2019      0.0000       0.0000       0.6108                    0.0  \n999666248/2019      3.8498       0.0000       0.0000                    0.0  \n\n[28863 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bygg_sum_0</th>\n      <th>hvete_sum_0</th>\n      <th>havre_sum_0</th>\n      <th>rug_og_rughvete_sum_0</th>\n      <th>bygg_sum_1</th>\n      <th>hvete_sum_1</th>\n      <th>havre_sum_1</th>\n      <th>rug_og_rughvete_sum_1</th>\n      <th>bygg_sum_2</th>\n      <th>hvete_sum_2</th>\n      <th>havre_sum_2</th>\n      <th>rug_og_rughvete_sum_2</th>\n      <th>bygg_sum_3</th>\n      <th>hvete_sum_3</th>\n      <th>havre_sum_3</th>\n      <th>rug_og_rughvete_sum_3</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>1.3687</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2050</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.0620</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2445</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2.9200</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>4.7596</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>6.4999</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>11.7227</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.8870</td>\n      <td>0.6015</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.4844</td>\n      <td>0.2770</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.2717</td>\n      <td>0.4869</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.0643</td>\n      <td>2.5620</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>1.7688</td>\n      <td>0.4413</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>3.3676</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.7060</td>\n      <td>1.4768</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2838</td>\n      <td>1.0750</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999640001/2019</th>\n      <td>0.0000</td>\n      <td>21.5508</td>\n      <td>4.7821</td>\n      <td>0.0</td>\n      <td>14.6406</td>\n      <td>0.0000</td>\n      <td>4.8990</td>\n      <td>0.0</td>\n      <td>9.4914</td>\n      <td>33.1335</td>\n      <td>5.0059</td>\n      <td>0.0</td>\n      <td>8.4269</td>\n      <td>6.3109</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999659209/2019</th>\n      <td>0.0000</td>\n      <td>2.2603</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.8102</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.1576</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.5396</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999662730/2019</th>\n      <td>0.0000</td>\n      <td>5.1119</td>\n      <td>9.7433</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.9122</td>\n      <td>10.4515</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>4.7917</td>\n      <td>8.2873</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.8919</td>\n      <td>5.8078</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999665462/2019</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.1122</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.6108</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999666248/2019</th>\n      <td>9.5523</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>9.8484</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>8.5110</td>\n      <td>0.0</td>\n      <td>3.8498</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28863 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical = ku.get_historical_production(kornmo, deliveries.year.unique(), 4)\n",
    "historical = deliveries.merge(historical, how='left').fillna(0)\n",
    "historical[\"key\"] = historical.orgnr.astype(str) + \"/\" + historical.year.astype(str)\n",
    "historical = historical.drop(columns=deliveries.columns)\n",
    "historical = historical.drop_duplicates(subset='key')\n",
    "historical = historical.set_index(\"key\")\n",
    "#historical = filter_by_years(years, historical)\n",
    "\n",
    "historical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sunlight data...\n",
      "Number of loaded entries: 30462\n",
      "Loading daydegree5 data...\n",
      "Number of loaded entries: 30462\n",
      "Loading ground data...\n",
      "Number of loaded entries: 30462\n",
      "Loading weather data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\frostdataset.py:107: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  weather_data = weather_data.append(weather, ignore_index=True)\n",
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\frostdataset.py:107: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  weather_data = weather_data.append(weather, ignore_index=True)\n",
      "D:\\OneDrive - Universitetet i Agder\\Master Thesis\\kornmo-master-thesis\\kornmo\\frostdataset.py:107: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  weather_data = weather_data.append(weather, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data entries loaded: 33003\n",
      "Merged 859 features of temp and precip data, 219 features of sunlight data, 216 features of daydegree data, 216 features of ground data to a total of 1504 features\n"
     ]
    },
    {
     "data": {
      "text/plain": "                growth_start_day  min_temp0  min_temp1  min_temp2  min_temp3  \\\nkey                                                                            \n811555762/2017          0.061905   0.491667   0.411667   0.421667   0.496667   \n811580082/2017          0.038095   0.505000   0.521667   0.560000   0.543333   \n811675792/2017          0.114286   0.485000   0.435000   0.503333   0.500000   \n811935662/2017          0.114286   0.491667   0.465000   0.473333   0.466667   \n812075322/2017          0.114286   0.458333   0.400000   0.440000   0.458333   \n...                          ...        ...        ...        ...        ...   \n997229789/2019          0.219048   0.456667   0.445000   0.423333   0.341667   \n997237269/2019          0.233333   0.418333   0.371667   0.486667   0.481667   \n997365747/2019          0.219048   0.405000   0.401667   0.388333   0.216667   \n997690877/2019          0.219048   0.488333   0.485000   0.433333   0.328333   \n998726581/2019          0.114286   0.451667   0.435000   0.575000   0.528333   \n\n                min_temp4  min_temp5  min_temp6  min_temp7  min_temp8  ...  \\\nkey                                                                    ...   \n811555762/2017   0.486667   0.448333   0.391667   0.361667   0.406667  ...   \n811580082/2017   0.526667   0.473333   0.413333   0.446667   0.560000  ...   \n811675792/2017   0.450000   0.430000   0.390000   0.300000   0.490000  ...   \n811935662/2017   0.438333   0.406667   0.370000   0.411667   0.488333  ...   \n812075322/2017   0.430000   0.410000   0.398333   0.300000   0.440000  ...   \n...                   ...        ...        ...        ...        ...  ...   \n997229789/2019   0.291667   0.281667   0.326667   0.396667   0.386667  ...   \n997237269/2019   0.415000   0.421667   0.453333   0.358333   0.320000  ...   \n997365747/2019   0.181667   0.143333   0.296667   0.383333   0.270000  ...   \n997690877/2019   0.250000   0.210000   0.313333   0.396667   0.268333  ...   \n998726581/2019   0.505000   0.506667   0.538333   0.508333   0.503333  ...   \n\n                 day_204  day_205  day_206   day_207   day_208   day_209  \\\nkey                                                                        \n811555762/2017  0.000000     0.00    0.000  0.000000  0.000000  0.000000   \n811580082/2017  0.285714     0.00    0.125  0.111111  0.000000  0.000000   \n811675792/2017  0.142857     0.25    0.125  0.111111  0.142857  0.142857   \n811935662/2017  0.142857     0.00    0.125  0.111111  0.285714  0.142857   \n812075322/2017  0.285714     0.50    0.125  0.222222  0.285714  0.285714   \n...                  ...      ...      ...       ...       ...       ...   \n997229789/2019       NaN      NaN      NaN       NaN       NaN       NaN   \n997237269/2019       NaN      NaN      NaN       NaN       NaN       NaN   \n997365747/2019  0.285714     0.50    0.125  0.111111  0.142857  0.142857   \n997690877/2019  0.285714     0.50    0.250  0.111111  0.142857  0.142857   \n998726581/2019  0.142857     0.25    0.125  0.111111  0.142857  0.142857   \n\n                 day_210   day_211   day_212   day_213  \nkey                                                     \n811555762/2017  0.000000  0.000000  0.000000  0.000000  \n811580082/2017  0.000000  0.111111  0.000000  0.222222  \n811675792/2017  0.285714  0.111111  0.000000  0.111111  \n811935662/2017  0.142857  0.111111  0.000000  0.000000  \n812075322/2017  0.285714  0.222222  0.000000  0.222222  \n...                  ...       ...       ...       ...  \n997229789/2019       NaN       NaN       NaN       NaN  \n997237269/2019       NaN       NaN       NaN       NaN  \n997365747/2019  0.142857  0.111111  0.111111  0.111111  \n997690877/2019  0.142857  0.111111  0.111111  0.222222  \n998726581/2019  0.285714  0.333333  0.333333  0.000000  \n\n[30873 rows x 1502 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>growth_start_day</th>\n      <th>min_temp0</th>\n      <th>min_temp1</th>\n      <th>min_temp2</th>\n      <th>min_temp3</th>\n      <th>min_temp4</th>\n      <th>min_temp5</th>\n      <th>min_temp6</th>\n      <th>min_temp7</th>\n      <th>min_temp8</th>\n      <th>...</th>\n      <th>day_204</th>\n      <th>day_205</th>\n      <th>day_206</th>\n      <th>day_207</th>\n      <th>day_208</th>\n      <th>day_209</th>\n      <th>day_210</th>\n      <th>day_211</th>\n      <th>day_212</th>\n      <th>day_213</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>0.061905</td>\n      <td>0.491667</td>\n      <td>0.411667</td>\n      <td>0.421667</td>\n      <td>0.496667</td>\n      <td>0.486667</td>\n      <td>0.448333</td>\n      <td>0.391667</td>\n      <td>0.361667</td>\n      <td>0.406667</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>0.038095</td>\n      <td>0.505000</td>\n      <td>0.521667</td>\n      <td>0.560000</td>\n      <td>0.543333</td>\n      <td>0.526667</td>\n      <td>0.473333</td>\n      <td>0.413333</td>\n      <td>0.446667</td>\n      <td>0.560000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.114286</td>\n      <td>0.485000</td>\n      <td>0.435000</td>\n      <td>0.503333</td>\n      <td>0.500000</td>\n      <td>0.450000</td>\n      <td>0.430000</td>\n      <td>0.390000</td>\n      <td>0.300000</td>\n      <td>0.490000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.285714</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.114286</td>\n      <td>0.491667</td>\n      <td>0.465000</td>\n      <td>0.473333</td>\n      <td>0.466667</td>\n      <td>0.438333</td>\n      <td>0.406667</td>\n      <td>0.370000</td>\n      <td>0.411667</td>\n      <td>0.488333</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>0.114286</td>\n      <td>0.458333</td>\n      <td>0.400000</td>\n      <td>0.440000</td>\n      <td>0.458333</td>\n      <td>0.430000</td>\n      <td>0.410000</td>\n      <td>0.398333</td>\n      <td>0.300000</td>\n      <td>0.440000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.125</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.285714</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>997229789/2019</th>\n      <td>0.219048</td>\n      <td>0.456667</td>\n      <td>0.445000</td>\n      <td>0.423333</td>\n      <td>0.341667</td>\n      <td>0.291667</td>\n      <td>0.281667</td>\n      <td>0.326667</td>\n      <td>0.396667</td>\n      <td>0.386667</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>997237269/2019</th>\n      <td>0.233333</td>\n      <td>0.418333</td>\n      <td>0.371667</td>\n      <td>0.486667</td>\n      <td>0.481667</td>\n      <td>0.415000</td>\n      <td>0.421667</td>\n      <td>0.453333</td>\n      <td>0.358333</td>\n      <td>0.320000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>997365747/2019</th>\n      <td>0.219048</td>\n      <td>0.405000</td>\n      <td>0.401667</td>\n      <td>0.388333</td>\n      <td>0.216667</td>\n      <td>0.181667</td>\n      <td>0.143333</td>\n      <td>0.296667</td>\n      <td>0.383333</td>\n      <td>0.270000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>997690877/2019</th>\n      <td>0.219048</td>\n      <td>0.488333</td>\n      <td>0.485000</td>\n      <td>0.433333</td>\n      <td>0.328333</td>\n      <td>0.250000</td>\n      <td>0.210000</td>\n      <td>0.313333</td>\n      <td>0.396667</td>\n      <td>0.268333</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.250</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>998726581/2019</th>\n      <td>0.114286</td>\n      <td>0.451667</td>\n      <td>0.435000</td>\n      <td>0.575000</td>\n      <td>0.528333</td>\n      <td>0.505000</td>\n      <td>0.506667</td>\n      <td>0.538333</td>\n      <td>0.508333</td>\n      <td>0.503333</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.142857</td>\n      <td>0.285714</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>30873 rows × 1502 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunlight_data = get_interpolated_data(years, 'sunlight')\n",
    "daydegree5_data = get_interpolated_data(years, 'daydegree5').drop(columns=['longitude', 'latitude', 'elevation'])\n",
    "ground_data = get_proximity_data(years, 'ground')\n",
    "temp_and_precip_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "weather_data = temp_and_precip_data.merge(sunlight_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(daydegree5_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(ground_data, how='left', on=['orgnr', 'year'])\n",
    "\n",
    "print(f\"Merged {temp_and_precip_data.shape[1]} features of temp and precip data, {sunlight_data.shape[1]} features of sunlight data, {daydegree5_data.shape[1]} features of daydegree data, {ground_data.shape[1]} features of ground data to a total of {weather_data.shape[1]} features\")\n",
    "\n",
    "#weather_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "\n",
    "weather_data[\"key\"] = weather_data.orgnr.astype(int).astype(str) + \"/\" + weather_data.year.astype(int).astype(str)\n",
    "weather_data.drop(columns=[\"year\", \"orgnr\"], inplace=True)\n",
    "weather_data = weather_data.drop_duplicates(subset=[\"key\"])\n",
    "weather_data = weather_data.set_index(\"key\")\n",
    "weather_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Combine dataset\n",
    "\n",
    "# sat_img_path = 'C:/'\n",
    "# from sentinel.storage import SentinelDataset\n",
    "# print(\"Reading sentinel_100x100_0.h5\")\n",
    "# ds0 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_0.h5\")\n",
    "# print(\"Reading sentinel_100x100_1.h5\")\n",
    "# ds1 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_1.h5\")\n",
    "# print(\"Combining both\")\n",
    "# SentinelDataset.combine_datasets([ds0, ds1], \"E:/combined_compressed.h5\", compression=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kornmo.sentinel.storage import SentinelDataset\n",
    "sat_img_path = 'E:/MasterThesisData/Satellite_Images'\n",
    "sd = SentinelDataset(f\"{sat_img_path}/sentinel_images_combined_uncompressed_100x100.h5\")\n",
    "train, val = sd.to_iterator().split(rand_seed='abc')\n",
    "\n",
    "def add_historical(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" in historical.index.values:\n",
    "        h_data = historical.loc[f\"{orgnr}/{year}\"]\n",
    "        return {'historical': h_data.values }\n",
    "    else:\n",
    "        return []\n",
    "def add_weather(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" not in weather_data.index:\n",
    "        return []\n",
    "    wd = weather_data.loc[f\"{orgnr}/{year}\"]\n",
    "    # min_temps = [value for key, value in wd.items() if key.startswith(\"min_temp\")]\n",
    "    # mean_temps = [value for key, value in wd.items() if key.startswith(\"mean_temp\")]\n",
    "    # max_temps = [value for key, value in wd.items() if key.startswith(\"max_temp\")]\n",
    "    # total_rain = [value for key, value in wd.items() if key.startswith(\"total_rain\")]\n",
    "    # stacked = np.stack((min_temps, mean_temps, max_temps, total_rain), axis=1)\n",
    "\n",
    "    return { 'weather': wd.values }\n",
    "\n",
    "def add_grain_types(orgnr, year, data):\n",
    "    samples = deliveries.loc[[f\"{orgnr}/{year}\"]]\n",
    "\n",
    "    all_grains = []\n",
    "    for _, row in samples.iterrows():\n",
    "        sample = {}\n",
    "        if row.bygg: sample[\"type\"] = (1,0,0,0)\n",
    "        elif row.havre: sample[\"type\"] = (0,1,0,0)\n",
    "        elif row.rug_og_rughvete: sample[\"type\"] = (0,0,1,0)\n",
    "        elif row.hvete: sample[\"type\"] = (0,0,0,1)\n",
    "\n",
    "        sample[\"areal\"] = row[\"areal\"]\n",
    "        sample[\"lat\"] = row[\"lat\"]\n",
    "        sample[\"elevation\"] = row[\"elevation\"]\n",
    "        sample[\"yield\"] = row[\"yield\"]\n",
    "        sample['fulldyrket'] = row['fulldyrket']\n",
    "        sample['overflatedyrket'] = row['overflatedyrket']\n",
    "        sample['tilskudd_dyr'] = row['tilskudd_dyr']\n",
    "        all_grains.append(sample)\n",
    "\n",
    "    return all_grains\n",
    "\n",
    "train = train.with_data(add_historical, True)\\\n",
    "             .with_data(add_weather, True)\\\n",
    "             .with_data(add_grain_types, True)\n",
    "\n",
    "val = val.with_data(add_historical, True)\\\n",
    "         .with_data(add_weather, True)\\\n",
    "         .with_data(add_grain_types, True)\n",
    "\n",
    "#13597\n",
    "#13582\n",
    "#12876\n",
    "#3400\n",
    "#3395\n",
    "#3182"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['2017', '2018', '2019']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('data/masks/nibio_disposed_properties_masks.h5', \"r+\") as out_file:\n",
    "    print(out_file['masks']['811555762'].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 19004\n",
      "val samples: 4710\n"
     ]
    }
   ],
   "source": [
    "from kornmo.mask.mask_dataset import MaskDataset\n",
    "from kornmo.mask.utils import add_mask_as_channel, apply_mask_to_image_series\n",
    "\n",
    "mask_dataset_path = \"Edata/masks/nibio_disposed_properties_masks.h5\"\n",
    "mask_dataset = MaskDataset(mask_dataset_path)\n",
    "#print(mask_dataset.labels)\n",
    "\n",
    "mask_iterator = mask_dataset.get_iterator()\n",
    "mask_dict = {}\n",
    "for orgnr, year, mask in mask_iterator:\n",
    "    mask_dict[f'{orgnr}/{year}'] = mask\n",
    "\n",
    "def apply_mask(orgnr, year, imgs):\n",
    "    mask = mask_dict[f'{orgnr}/{year}']\n",
    "    return apply_mask_to_image_series(mask, imgs)\n",
    "\n",
    "train = train.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "val = val.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "\n",
    "print(f\"train samples: {len(train)}\")\n",
    "print(f\"val samples: {len(val)}\")\n",
    "#19003\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented samples: 95020\n",
      "Validation samples: 4710\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "# from tensorflow.data.experimental import assert_cardinality\n",
    "from kornmo.sentinel.transform import salt_n_pepper, rotate180, rotate90\n",
    "\n",
    "stride = 10\n",
    "def top_left(imgs):\n",
    "    return imgs[...,:-stride, :-stride,:]\n",
    "def top_right(imgs):\n",
    "    return imgs[...,:-stride, stride:,:]\n",
    "def bot_left(imgs):\n",
    "    return imgs[...,stride:, :-stride,:]\n",
    "def bot_right(imgs):\n",
    "    return imgs[...,stride:, stride:,:]\n",
    "def center(imgs):\n",
    "    s = stride//2\n",
    "    return imgs[...,s:-s, s:-s,:]\n",
    "\n",
    "def rotate_random(imgs):\n",
    "    angle = np.random.rand(30) * 6.28\n",
    "    return tfa.image.rotate(imgs, angle)\n",
    "\n",
    "augmented_dataset = train\\\n",
    "    .transform(apply_mask)\\\n",
    "    .transform(salt_n_pepper())\\\n",
    "    .augment([center, top_left, top_right, bot_left, bot_right], keep_original=False)\\\n",
    "    .transform(rotate_random)\n",
    "\n",
    "def apply_output(orgnr, year, img_source, data):\n",
    "    features = data[\"areal\"], *data[\"type\"]\n",
    "    output = data[\"yield\"]\n",
    "    weather = data[\"weather\"][1:]\n",
    "    return {\"cnn_input\": img_source[0:30], \"feature_input\": features, \"weather_input\": weather}, output\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    augmented_dataset.apply(apply_output).shuffled(),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(tf.data.experimental.assert_cardinality(len(augmented_dataset)))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val.transform(apply_mask).transform(center).apply(apply_output),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(tf.data.experimental.assert_cardinality(len(val)))\n",
    "\n",
    "print(f\"Augmented samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "#95015\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "313/313 [==============================] - 4988s 16s/step - loss: 0.1307 - val_loss: 0.1065\n",
      "Epoch 2/70\n",
      "313/313 [==============================] - 4615s 15s/step - loss: 0.1107 - val_loss: 0.1136\n",
      "Epoch 3/70\n",
      "313/313 [==============================] - 4458s 14s/step - loss: 0.1042 - val_loss: 0.1152\n",
      "Epoch 4/70\n",
      "313/313 [==============================] - 4592s 15s/step - loss: 0.1025 - val_loss: 0.1045\n",
      "Epoch 5/70\n",
      "313/313 [==============================] - 4665s 15s/step - loss: 0.1040 - val_loss: 0.0989\n",
      "Epoch 6/70\n",
      "313/313 [==============================] - 4644s 15s/step - loss: 0.0989 - val_loss: 0.1015\n",
      "Epoch 7/70\n",
      "313/313 [==============================] - 4659s 15s/step - loss: 0.0985 - val_loss: 0.1005\n",
      "Epoch 8/70\n",
      "313/313 [==============================] - 4476s 14s/step - loss: 0.0961 - val_loss: 0.0937\n",
      "Epoch 9/70\n",
      "313/313 [==============================] - 4030s 13s/step - loss: 0.0958 - val_loss: 0.0952\n",
      "Epoch 10/70\n",
      "313/313 [==============================] - 4014s 13s/step - loss: 0.0960 - val_loss: 0.0932\n",
      "Epoch 11/70\n",
      "313/313 [==============================] - 4014s 13s/step - loss: 0.0935 - val_loss: 0.0915\n",
      "Epoch 12/70\n",
      "313/313 [==============================] - 4015s 13s/step - loss: 0.0911 - val_loss: 0.0892\n",
      "Epoch 13/70\n",
      "313/313 [==============================] - 4012s 13s/step - loss: 0.0898 - val_loss: 0.0920\n",
      "Epoch 14/70\n",
      "313/313 [==============================] - 4075s 13s/step - loss: 0.0898 - val_loss: 0.0875\n",
      "Epoch 15/70\n",
      "313/313 [==============================] - 4565s 15s/step - loss: 0.0897 - val_loss: 0.1002\n",
      "Epoch 16/70\n",
      "313/313 [==============================] - 4347s 14s/step - loss: 0.0873 - val_loss: 0.0868\n",
      "Epoch 17/70\n",
      "313/313 [==============================] - 4290s 14s/step - loss: 0.0877 - val_loss: 0.0903\n",
      "Epoch 18/70\n",
      "313/313 [==============================] - 4542s 15s/step - loss: 0.0868 - val_loss: 0.0850\n",
      "Epoch 19/70\n",
      "313/313 [==============================] - 4192s 13s/step - loss: 0.0855 - val_loss: 0.0863\n",
      "Epoch 20/70\n",
      "313/313 [==============================] - 4288s 14s/step - loss: 0.0842 - val_loss: 0.0854\n",
      "Epoch 21/70\n",
      "313/313 [==============================] - 4388s 14s/step - loss: 0.0844 - val_loss: 0.0832\n",
      "Epoch 22/70\n",
      "313/313 [==============================] - 4522s 14s/step - loss: 0.0844 - val_loss: 0.0843\n",
      "Epoch 23/70\n",
      "313/313 [==============================] - 4515s 14s/step - loss: 0.0845 - val_loss: 0.0821\n",
      "Epoch 24/70\n",
      "313/313 [==============================] - 4523s 14s/step - loss: 0.0823 - val_loss: 0.0803\n",
      "Epoch 25/70\n",
      "313/313 [==============================] - 4607s 15s/step - loss: 0.0825 - val_loss: 0.0910\n",
      "Epoch 26/70\n",
      "313/313 [==============================] - 4914s 16s/step - loss: 0.0823 - val_loss: 0.0829\n",
      "Epoch 27/70\n",
      "313/313 [==============================] - 4625s 15s/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 28/70\n",
      "313/313 [==============================] - 4559s 15s/step - loss: 0.0806 - val_loss: 0.0826\n",
      "Epoch 29/70\n",
      "313/313 [==============================] - 4008s 13s/step - loss: 0.0802 - val_loss: 0.0796\n",
      "Epoch 30/70\n",
      "313/313 [==============================] - 4018s 13s/step - loss: 0.0801 - val_loss: 0.0803\n",
      "Epoch 31/70\n",
      "313/313 [==============================] - 4018s 13s/step - loss: 0.0793 - val_loss: 0.0788\n",
      "Epoch 32/70\n",
      "313/313 [==============================] - 4008s 13s/step - loss: 0.0796 - val_loss: 0.0807\n",
      "Epoch 33/70\n",
      "313/313 [==============================] - 4019s 13s/step - loss: 0.0794 - val_loss: 0.0792\n",
      "Epoch 34/70\n",
      "313/313 [==============================] - 4015s 13s/step - loss: 0.0788 - val_loss: 0.0812\n",
      "Epoch 35/70\n",
      "313/313 [==============================] - 4023s 13s/step - loss: 0.0796 - val_loss: 0.0797\n",
      "Epoch 36/70\n",
      "313/313 [==============================] - 4017s 13s/step - loss: 0.0789 - val_loss: 0.0811\n",
      "Epoch 37/70\n",
      "313/313 [==============================] - 4319s 14s/step - loss: 0.0781 - val_loss: 0.0827\n",
      "Epoch 38/70\n",
      "313/313 [==============================] - 4533s 14s/step - loss: 0.0780 - val_loss: 0.0787\n",
      "Epoch 39/70\n",
      "313/313 [==============================] - 4242s 14s/step - loss: 0.0775 - val_loss: 0.0791\n",
      "Epoch 40/70\n",
      "313/313 [==============================] - 4329s 14s/step - loss: 0.0794 - val_loss: 0.0791\n",
      "Epoch 41/70\n",
      "313/313 [==============================] - 4390s 14s/step - loss: 0.0759 - val_loss: 0.0814\n",
      "Epoch 42/70\n",
      "313/313 [==============================] - 4656s 15s/step - loss: 0.0778 - val_loss: 0.0809\n",
      "Epoch 43/70\n",
      "313/313 [==============================] - 4679s 15s/step - loss: 0.0778 - val_loss: 0.0791\n",
      "Epoch 44/70\n",
      "313/313 [==============================] - 4536s 14s/step - loss: 0.0771 - val_loss: 0.0790\n",
      "Epoch 45/70\n",
      "313/313 [==============================] - 4491s 14s/step - loss: 0.0765 - val_loss: 0.0891\n",
      "Epoch 46/70\n",
      "313/313 [==============================] - 4357s 14s/step - loss: 0.0771 - val_loss: 0.0791\n",
      "Epoch 47/70\n",
      "313/313 [==============================] - 4451s 14s/step - loss: 0.0762 - val_loss: 0.0847\n",
      "Epoch 48/70\n",
      "313/313 [==============================] - 4580s 15s/step - loss: 0.0763 - val_loss: 0.0805\n",
      "Epoch 49/70\n",
      "313/313 [==============================] - 4163s 13s/step - loss: 0.0757 - val_loss: 0.0776\n",
      "Epoch 50/70\n",
      "313/313 [==============================] - 4083s 13s/step - loss: 0.0759 - val_loss: 0.0790\n",
      "Epoch 51/70\n",
      "313/313 [==============================] - 4081s 13s/step - loss: 0.0746 - val_loss: 0.0803\n",
      "Epoch 52/70\n",
      "313/313 [==============================] - 4101s 13s/step - loss: 0.0758 - val_loss: 0.0783\n",
      "Epoch 53/70\n",
      "313/313 [==============================] - 4083s 13s/step - loss: 0.0747 - val_loss: 0.0789\n",
      "Epoch 54/70\n",
      "313/313 [==============================] - 4075s 13s/step - loss: 0.0746 - val_loss: 0.0780\n",
      "Epoch 55/70\n",
      "313/313 [==============================] - 4079s 13s/step - loss: 0.0743 - val_loss: 0.0856\n",
      "Epoch 56/70\n",
      "313/313 [==============================] - 4140s 13s/step - loss: 0.0754 - val_loss: 0.0782\n",
      "Epoch 57/70\n",
      "313/313 [==============================] - 4342s 14s/step - loss: 0.0732 - val_loss: 0.0826\n",
      "Epoch 58/70\n",
      "313/313 [==============================] - 4217s 13s/step - loss: 0.0745 - val_loss: 0.0776\n",
      "Epoch 59/70\n",
      "313/313 [==============================] - 4473s 14s/step - loss: 0.0739 - val_loss: 0.0823\n",
      "Epoch 60/70\n",
      "313/313 [==============================] - 4423s 14s/step - loss: 0.0729 - val_loss: 0.0810\n",
      "Epoch 61/70\n",
      "313/313 [==============================] - 4443s 14s/step - loss: 0.0723 - val_loss: 0.0783\n",
      "Epoch 62/70\n",
      "313/313 [==============================] - 4485s 14s/step - loss: 0.0738 - val_loss: 0.0777\n",
      "Epoch 63/70\n",
      "313/313 [==============================] - 4305s 14s/step - loss: 0.0729 - val_loss: 0.0797\n",
      "Epoch 64/70\n",
      "313/313 [==============================] - 4353s 14s/step - loss: 0.0736 - val_loss: 0.0815\n",
      "Epoch 65/70\n",
      "313/313 [==============================] - 4495s 14s/step - loss: 0.0719 - val_loss: 0.0766\n",
      "Epoch 66/70\n",
      "313/313 [==============================] - 4527s 14s/step - loss: 0.0724 - val_loss: 0.0783\n",
      "Epoch 67/70\n",
      "313/313 [==============================] - 4409s 14s/step - loss: 0.0718 - val_loss: 0.0777\n",
      "Epoch 68/70\n",
      "313/313 [==============================] - 4022s 13s/step - loss: 0.0718 - val_loss: 0.0795\n",
      "Epoch 69/70\n",
      "313/313 [==============================] - 4017s 13s/step - loss: 0.0716 - val_loss: 0.0775\n",
      "Epoch 70/70\n",
      "313/313 [==============================] - 4017s 13s/step - loss: 0.0707 - val_loss: 0.0790\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "def CNN(input_dim, output_dim):\n",
    "    input_layer = layers.Input(shape=input_dim)\n",
    "    y = layers.Conv2D(16, (3, 3), activation=tf.nn.relu, padding='same')(input_layer)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(output_dim, activation=tf.nn.relu)(y)\n",
    "\n",
    "    return models.Model(inputs=[input_layer], outputs=[y], name=\"SingleImageCNN\")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    './training',\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "callbacks = [callback, model_checkpoint]\n",
    "\n",
    "restart = True\n",
    "if restart:\n",
    "\n",
    "    scnn = CNN((90, 90, 12), 64)\n",
    "    #scnn.summary(line_length=130)\n",
    "    input_weather = layers.Input(shape=1501, name=\"weather_input\") #shape = 856 / 1501\n",
    "    t_wm = layers.Reshape((19, 79))(input_weather) # (4, 214) / (19, 79)\n",
    "    t_wm = layers.Permute((2, 1))(t_wm)\n",
    "    t_wm = layers.Conv1D(64, 50, activation=tf.nn.relu)(t_wm) # (64, 7, 7) / (64, 50)\n",
    "\n",
    "    input_cnn = layers.Input(shape=(30, 90, 90, 12), name=\"cnn_input\")\n",
    "\n",
    "    feature_input = layers.Input(shape=(5,), name=\"feature_input\")\n",
    "    feature_repeated = layers.RepeatVector(30)(feature_input)\n",
    "\n",
    "    cnn = layers.TimeDistributed(scnn)(input_cnn)\n",
    "    cnn = layers.Concatenate(axis=2)([cnn, feature_repeated, t_wm])\n",
    "    cnn = layers.GRU(128, return_sequences=False)(cnn)\n",
    "    cnn = layers.Flatten()(cnn)\n",
    "    cnn = layers.Dense(128, activation=tf.nn.relu)(cnn)\n",
    "    cnn = layers.Dense(1)(cnn)\n",
    "\n",
    "    cnn = models.Model(inputs=[input_weather, input_cnn, feature_input], outputs=cnn, name=\"CNN\")\n",
    "    #cnn.summary(line_length=130)\n",
    "\n",
    "    cnn.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_absolute_error')\n",
    "\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=70,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "else:\n",
    "    cnn = load_model('./training/epoch_2.hdf5')\n",
    "    # update the learning rate\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denormalized MAE: 78.96059544402297\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n# loss = []\\n# val_loss = []\\n\\n\\nsns.set_style(\\'whitegrid\\')\\nsns.set_context(\"paper\")\\n\\nplt.xlabel(\\'Epoch\\')\\nplt.ylabel(\"Loss\")\\nplt.plot(loss, label=\"loss\")\\nplt.plot(val_loss, label=\"val_loss\")\\nplt.legend()\\nplt.title(\"Mean absolute error loss\")\\nplt.savefig(f\\'E:/MasterThesisData/models/hybrid_more_features.png\\', dpi=600)\\nplt.grid()\\n'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def denormalize(df, lower: float, upper: float):\n",
    "    \"\"\"\n",
    "    Denormalizes DataFrame\n",
    "    :param df: The DataFrame where all columns will be denormalized.\n",
    "    :param lower: The denormalized value of 0\n",
    "    :param upper: The denormalized value of 1\n",
    "    :return: The denormalized DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    return df * (upper - lower) + lower\n",
    "\n",
    "\n",
    "def plot_history(history, save_file: str=None):\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(history.history['loss'], label=\"loss\")\n",
    "    plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Mean absolute error loss\")\n",
    "    if save_file is not None:\n",
    "        plt.savefig(save_file, dpi=600)\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "plot_history(cnn_history, save_file=\"E:/MasterThesisData/models/hybrid_more_features_history.png\")\n",
    "\n",
    "\n",
    "predictions = cnn.predict(val_dataset.batch(32).prefetch(2))\n",
    "predictions = np.array(predictions).flatten()\n",
    "facts = val.apply(lambda orgnr, year, img, data: data[\"yield\"]).as_array()\n",
    "absolute_error = np.abs(predictions - facts)\n",
    "print(f\"Denormalized MAE: {denormalize(absolute_error.mean(), 0, 1000)}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}