{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from kornmo import KornmoDataset\n",
    "from geodata import get_farmer_elevation\n",
    "import kornmo_utils as ku\n",
    "from frostdataset import FrostDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def filter_by_years(years, data):\n",
    "    return data[data['year'].isin(years)]\n",
    "\n",
    "def get_interpolated_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/nn_interpolated/{weather_feature}/{weather_feature}_interpolated_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    # Drop columns containing 'Unnamed'\n",
    "    data.drop(columns=[col for col in data.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year', 'longitude', 'latitude', 'elevation']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_proximity_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/by_proximity/{weather_feature}/{weather_feature}_by_proximity_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.drop(columns=['ws_id'], inplace=True)\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deliveries...\n",
      "Number of deliveries loaded: 88624\n"
     ]
    },
    {
     "data": {
      "text/plain": "                year      orgnr  kommunenr  gaardsnummer  bruksnummer  \\\nkey                                                                     \n811555762/2017  2017  811555762       1653            24            2   \n811580082/2017  2017  811580082       1124            25            5   \n811675792/2017  2017  811675792        709          2023           12   \n811675792/2017  2017  811675792        709          2023           12   \n811935662/2017  2017  811935662        125           207            1   \n...              ...        ...        ...           ...          ...   \n999659209/2020  2020  999659209       3812            31           64   \n999662730/2020  2020  999662730       3802           247            1   \n999662730/2020  2020  999662730       3802           247            1   \n999665462/2020  2020  999665462       3028            69            1   \n999666248/2020  2020  999666248       3030           252           10   \n\n                festenummer  fulldyrket  overflatedyrket  tilskudd_dyr  \\\nkey                                                                      \n811555762/2017            0    0.007241              0.0      0.000000   \n811580082/2017            0    0.110575              0.0      0.335581   \n811675792/2017            0    0.014180              0.0      0.000000   \n811675792/2017            0    0.014180              0.0      0.000000   \n811935662/2017            0    0.014331              0.0      0.000000   \n...                     ...         ...              ...           ...   \n999659209/2020            0    0.007543              0.0      0.000000   \n999662730/2020            0    0.043898              0.0      0.000000   \n999662730/2020            0    0.043898              0.0      0.000000   \n999665462/2020            0    0.039674              0.0      0.052484   \n999666248/2020            0    0.022477              0.0      0.000000   \n\n                levert     areal  bygg  havre  hvete  rug_og_rughvete  \\\nkey                                                                     \n811555762/2017   17067  0.017475   1.0    0.0    0.0              0.0   \n811580082/2017   81204  0.064477   1.0    0.0    0.0              0.0   \n811675792/2017   10902  0.020789   1.0    0.0    0.0              0.0   \n811675792/2017    2335  0.004218   0.0    0.0    1.0              0.0   \n811935662/2017   33166  0.031636   0.0    0.0    1.0              0.0   \n...                ...       ...   ...    ...    ...              ...   \n999659209/2020   32209  0.018078   0.0    0.0    0.0              1.0   \n999662730/2020  100087  0.065080   0.0    1.0    0.0              0.0   \n999662730/2020   39067  0.023802   0.0    0.0    1.0              0.0   \n999665462/2020   38686  0.034348   0.0    1.0    0.0              0.0   \n999666248/2020  100663  0.047906   0.0    1.0    0.0              0.0   \n\n                     lat  elevation     yield  \nkey                                            \n811555762/2017  0.959116   0.051198  0.289271  \n811580082/2017  0.891830   0.024510  0.377693  \n811675792/2017  0.896483   0.014706  0.155743  \n811675792/2017  0.896483   0.014706  0.155667  \n811935662/2017  0.907412   0.073529  0.312887  \n...                  ...        ...       ...  \n999659209/2020  0.898225   0.068627  0.528016  \n999662730/2020  0.902149   0.093137  0.461230  \n999662730/2020  0.902149   0.093137  0.488337  \n999665462/2020  0.905165   0.142157  0.336400  \n999666248/2020  0.909951   0.132353  0.629144  \n\n[60462 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>orgnr</th>\n      <th>kommunenr</th>\n      <th>gaardsnummer</th>\n      <th>bruksnummer</th>\n      <th>festenummer</th>\n      <th>fulldyrket</th>\n      <th>overflatedyrket</th>\n      <th>tilskudd_dyr</th>\n      <th>levert</th>\n      <th>areal</th>\n      <th>bygg</th>\n      <th>havre</th>\n      <th>hvete</th>\n      <th>rug_og_rughvete</th>\n      <th>lat</th>\n      <th>elevation</th>\n      <th>yield</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>2017</td>\n      <td>811555762</td>\n      <td>1653</td>\n      <td>24</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.007241</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>17067</td>\n      <td>0.017475</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.959116</td>\n      <td>0.051198</td>\n      <td>0.289271</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2017</td>\n      <td>811580082</td>\n      <td>1124</td>\n      <td>25</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.110575</td>\n      <td>0.0</td>\n      <td>0.335581</td>\n      <td>81204</td>\n      <td>0.064477</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.891830</td>\n      <td>0.024510</td>\n      <td>0.377693</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.014180</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>10902</td>\n      <td>0.020789</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155743</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.014180</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2335</td>\n      <td>0.004218</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155667</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>2017</td>\n      <td>811935662</td>\n      <td>125</td>\n      <td>207</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.014331</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>33166</td>\n      <td>0.031636</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.907412</td>\n      <td>0.073529</td>\n      <td>0.312887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999659209/2020</th>\n      <td>2020</td>\n      <td>999659209</td>\n      <td>3812</td>\n      <td>31</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0.007543</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>32209</td>\n      <td>0.018078</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.898225</td>\n      <td>0.068627</td>\n      <td>0.528016</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>2020</td>\n      <td>999662730</td>\n      <td>3802</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.043898</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>100087</td>\n      <td>0.065080</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.461230</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>2020</td>\n      <td>999662730</td>\n      <td>3802</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.043898</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>39067</td>\n      <td>0.023802</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.488337</td>\n    </tr>\n    <tr>\n      <th>999665462/2020</th>\n      <td>2020</td>\n      <td>999665462</td>\n      <td>3028</td>\n      <td>69</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.039674</td>\n      <td>0.0</td>\n      <td>0.052484</td>\n      <td>38686</td>\n      <td>0.034348</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.905165</td>\n      <td>0.142157</td>\n      <td>0.336400</td>\n    </tr>\n    <tr>\n      <th>999666248/2020</th>\n      <td>2020</td>\n      <td>999666248</td>\n      <td>3030</td>\n      <td>252</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.022477</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>100663</td>\n      <td>0.047906</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.909951</td>\n      <td>0.132353</td>\n      <td>0.629144</td>\n    </tr>\n  </tbody>\n</table>\n<p>60462 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [2017, 2018, 2019, 2020]\n",
    "frost = FrostDataset()\n",
    "kornmo = KornmoDataset()\n",
    "deliveries = kornmo.get_deliveries().pipe(ku.split_farmers_on_type)\n",
    "\n",
    "elevation_data = get_farmer_elevation()\n",
    "deliveries = deliveries.merge(elevation_data, on=['orgnr'], how='left').fillna(0)\n",
    "\n",
    "deliveries[\"yield\"] = ku.normalize(deliveries[\"levert\"]/deliveries[\"areal\"], 0, 1000)\n",
    "deliveries[\"areal\"] = ku.normalize(deliveries[\"areal\"])\n",
    "deliveries['fulldyrket'] = ku.normalize(deliveries['fulldyrket'])\n",
    "deliveries['overflatedyrket'] = ku.normalize(deliveries['overflatedyrket'])\n",
    "deliveries['tilskudd_dyr'] = ku.normalize(deliveries['tilskudd_dyr'])\n",
    "deliveries['lat'] = ku.normalize(deliveries['lat'])\n",
    "deliveries['elevation'] = ku.normalize(deliveries['elevation'])\n",
    "\n",
    "deliveries[\"key\"] = deliveries.orgnr.astype(str) + \"/\" + deliveries.year.astype(str)\n",
    "deliveries = deliveries.set_index(\"key\")\n",
    "deliveries = filter_by_years(years, deliveries)\n",
    "\n",
    "deliveries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical grants data...\n",
      "Historical data loaded for years 2013 to 2020.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                bygg_sum_0  hvete_sum_0  havre_sum_0  rug_og_rughvete_sum_0  \\\nkey                                                                           \n811555762/2017      1.3687       0.0000       0.0000                    0.0   \n811580082/2017      2.9200       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       0.0000       0.0000                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7688       0.4413       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020     14.6406       0.0000       4.8990                    0.0   \n999659209/2020      1.8102       0.0000       0.0000                    0.0   \n999662730/2020      0.0000       2.9122      10.4515                    0.0   \n999665462/2020      0.0000       0.0000       0.0000                    0.0   \n999666248/2020      0.0000       0.0000       9.8484                    0.0   \n\n                bygg_sum_1  hvete_sum_1  havre_sum_1  rug_og_rughvete_sum_1  \\\nkey                                                                           \n811555762/2017      2.2050       0.0000       0.0000                    0.0   \n811580082/2017      4.7596       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       2.8870       0.6015                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      3.3676       0.0000       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020      9.4914      33.1335       5.0059                    0.0   \n999659209/2020      0.0000       1.1576       0.0000                    0.0   \n999662730/2020      0.0000       4.7917       8.2873                    0.0   \n999665462/2020      0.0000       0.0000       2.1122                    0.0   \n999666248/2020      0.0000       0.0000       8.5110                    0.0   \n\n                bygg_sum_2  hvete_sum_2  havre_sum_2  rug_og_rughvete_sum_2  \\\nkey                                                                           \n811555762/2017      2.0620       0.0000       0.0000                    0.0   \n811580082/2017      6.4999       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       1.4844       0.2770                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7060       1.4768       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020      8.4269       6.3109       0.0000                    0.0   \n999659209/2020      0.0000       0.0000       1.5396                    0.0   \n999662730/2020      0.0000       1.8919       5.8078                    0.0   \n999665462/2020      0.0000       0.0000       0.6108                    0.0   \n999666248/2020      3.8498       0.0000       0.0000                    0.0   \n\n                bygg_sum_3  hvete_sum_3  havre_sum_3  rug_og_rughvete_sum_3  \nkey                                                                          \n811555762/2017      2.2445       0.0000       0.0000                    0.0  \n811580082/2017     11.7227       0.0000       0.0000                    0.0  \n811675792/2017      0.0000       2.2717       0.4869                    0.0  \n811935662/2017      1.0643       2.5620       0.0000                    0.0  \n812075322/2017      2.2838       1.0750       0.0000                    0.0  \n...                    ...          ...          ...                    ...  \n999640001/2020      0.0000      49.4732       0.0000                    0.0  \n999659209/2020      1.3426       0.0000       0.0000                    0.0  \n999662730/2020      0.0000       4.4841       8.6888                    0.0  \n999665462/2020      0.0000       0.0000       2.1835                    0.0  \n999666248/2020      9.5683       0.0000       0.0000                    0.0  \n\n[38478 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bygg_sum_0</th>\n      <th>hvete_sum_0</th>\n      <th>havre_sum_0</th>\n      <th>rug_og_rughvete_sum_0</th>\n      <th>bygg_sum_1</th>\n      <th>hvete_sum_1</th>\n      <th>havre_sum_1</th>\n      <th>rug_og_rughvete_sum_1</th>\n      <th>bygg_sum_2</th>\n      <th>hvete_sum_2</th>\n      <th>havre_sum_2</th>\n      <th>rug_og_rughvete_sum_2</th>\n      <th>bygg_sum_3</th>\n      <th>hvete_sum_3</th>\n      <th>havre_sum_3</th>\n      <th>rug_og_rughvete_sum_3</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>1.3687</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2050</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.0620</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2445</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2.9200</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>4.7596</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>6.4999</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>11.7227</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.8870</td>\n      <td>0.6015</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.4844</td>\n      <td>0.2770</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.2717</td>\n      <td>0.4869</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.0643</td>\n      <td>2.5620</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>1.7688</td>\n      <td>0.4413</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>3.3676</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.7060</td>\n      <td>1.4768</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2838</td>\n      <td>1.0750</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999640001/2020</th>\n      <td>14.6406</td>\n      <td>0.0000</td>\n      <td>4.8990</td>\n      <td>0.0</td>\n      <td>9.4914</td>\n      <td>33.1335</td>\n      <td>5.0059</td>\n      <td>0.0</td>\n      <td>8.4269</td>\n      <td>6.3109</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>49.4732</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999659209/2020</th>\n      <td>1.8102</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.1576</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.5396</td>\n      <td>0.0</td>\n      <td>1.3426</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>0.0000</td>\n      <td>2.9122</td>\n      <td>10.4515</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>4.7917</td>\n      <td>8.2873</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.8919</td>\n      <td>5.8078</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>4.4841</td>\n      <td>8.6888</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999665462/2020</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.1122</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.6108</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.1835</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999666248/2020</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>9.8484</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>8.5110</td>\n      <td>0.0</td>\n      <td>3.8498</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>9.5683</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>38478 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical = ku.get_historical_production(kornmo, deliveries.year.unique(), 4)\n",
    "historical = deliveries.merge(historical, how='left').fillna(0)\n",
    "historical[\"key\"] = historical.orgnr.astype(str) + \"/\" + historical.year.astype(str)\n",
    "historical = historical.drop(columns=deliveries.columns)\n",
    "historical = historical.drop_duplicates(subset='key')\n",
    "historical = historical.set_index(\"key\")\n",
    "#historical = filter_by_years(years, historical)\n",
    "\n",
    "historical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sunlight data...\n",
      "Number of loaded entries: 40616\n",
      "Loading daydegree5 data...\n",
      "Number of loaded entries: 40616\n",
      "Loading ground data...\n",
      "Number of loaded entries: 40616\n",
      "Loading weather data...\n",
      "Weather data entries loaded: 43157\n",
      "Merged 859 features of temp and precip data, 219 features of sunlight data, 216 features of daydegree data, 216 features of ground data to a total of 1504 features\n"
     ]
    },
    {
     "data": {
      "text/plain": "                growth_start_day  min_temp0  min_temp1  min_temp2  min_temp3  \\\nkey                                                                            \n811555762/2017          0.061905   0.491667   0.411667   0.421667   0.496667   \n811580082/2017          0.038095   0.505000   0.521667   0.560000   0.543333   \n811675792/2017          0.114286   0.485000   0.435000   0.503333   0.500000   \n811935662/2017          0.114286   0.491667   0.465000   0.473333   0.466667   \n812075322/2017          0.114286   0.458333   0.400000   0.440000   0.458333   \n...                          ...        ...        ...        ...        ...   \n869672092/2020          0.171429   0.383333   0.421667   0.428333   0.465000   \n995492008/2020          0.171429   0.360000   0.400000   0.430000   0.470000   \n914335027/2020          0.109524   0.495000   0.518333   0.506667   0.476667   \n997795016/2020          0.171429   0.445000   0.515000   0.485000   0.468333   \n968956779/2020          0.380952   0.273333   0.358333   0.428333   0.446667   \n\n                min_temp4  min_temp5  min_temp6  min_temp7  min_temp8  ...  \\\nkey                                                                    ...   \n811555762/2017   0.486667   0.448333   0.391667   0.361667   0.406667  ...   \n811580082/2017   0.526667   0.473333   0.413333   0.446667   0.560000  ...   \n811675792/2017   0.450000   0.430000   0.390000   0.300000   0.490000  ...   \n811935662/2017   0.438333   0.406667   0.370000   0.411667   0.488333  ...   \n812075322/2017   0.430000   0.410000   0.398333   0.300000   0.440000  ...   \n...                   ...        ...        ...        ...        ...  ...   \n869672092/2020   0.435000   0.421667   0.361667   0.510000   0.455000  ...   \n995492008/2020   0.435000   0.426667   0.368333   0.515000   0.445000  ...   \n914335027/2020   0.435000   0.421667   0.448333   0.558333   0.540000  ...   \n997795016/2020   0.406667   0.410000   0.408333   0.496667   0.510000  ...   \n968956779/2020   0.385000   0.453333   0.436667   0.475000   0.508333  ...   \n\n                 day_204  day_205  day_206   day_207   day_208   day_209  \\\nkey                                                                        \n811555762/2017  0.000000     0.00    0.000  0.000000  0.000000  0.000000   \n811580082/2017  0.285714     0.00    0.125  0.111111  0.000000  0.000000   \n811675792/2017  0.142857     0.25    0.125  0.111111  0.142857  0.111111   \n811935662/2017  0.142857     0.00    0.125  0.111111  0.285714  0.111111   \n812075322/2017  0.285714     0.50    0.125  0.222222  0.285714  0.222222   \n...                  ...      ...      ...       ...       ...       ...   \n869672092/2020  0.142857     0.25    0.000  0.222222  0.000000  0.111111   \n995492008/2020  0.142857     0.25    0.000  0.222222  0.000000  0.111111   \n914335027/2020  0.142857     0.25    0.125  0.222222  0.285714  0.222222   \n997795016/2020  0.000000     0.00    0.000  0.111111  0.142857  0.222222   \n968956779/2020  0.285714     0.50    0.250  0.222222  0.285714  0.222222   \n\n                 day_210   day_211   day_212   day_213  \nkey                                                     \n811555762/2017  0.000000  0.000000  0.000000  0.000000  \n811580082/2017  0.000000  0.111111  0.000000  0.222222  \n811675792/2017  0.285714  0.111111  0.000000  0.111111  \n811935662/2017  0.142857  0.111111  0.000000  0.000000  \n812075322/2017  0.285714  0.222222  0.000000  0.222222  \n...                  ...       ...       ...       ...  \n869672092/2020  0.000000  0.000000  0.000000  0.000000  \n995492008/2020  0.000000  0.000000  0.000000  0.000000  \n914335027/2020  0.142857  0.111111  0.222222  0.111111  \n997795016/2020  0.142857  0.111111  0.111111  0.111111  \n968956779/2020  0.285714  0.222222  0.111111  0.111111  \n\n[41027 rows x 1502 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>growth_start_day</th>\n      <th>min_temp0</th>\n      <th>min_temp1</th>\n      <th>min_temp2</th>\n      <th>min_temp3</th>\n      <th>min_temp4</th>\n      <th>min_temp5</th>\n      <th>min_temp6</th>\n      <th>min_temp7</th>\n      <th>min_temp8</th>\n      <th>...</th>\n      <th>day_204</th>\n      <th>day_205</th>\n      <th>day_206</th>\n      <th>day_207</th>\n      <th>day_208</th>\n      <th>day_209</th>\n      <th>day_210</th>\n      <th>day_211</th>\n      <th>day_212</th>\n      <th>day_213</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>0.061905</td>\n      <td>0.491667</td>\n      <td>0.411667</td>\n      <td>0.421667</td>\n      <td>0.496667</td>\n      <td>0.486667</td>\n      <td>0.448333</td>\n      <td>0.391667</td>\n      <td>0.361667</td>\n      <td>0.406667</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>0.038095</td>\n      <td>0.505000</td>\n      <td>0.521667</td>\n      <td>0.560000</td>\n      <td>0.543333</td>\n      <td>0.526667</td>\n      <td>0.473333</td>\n      <td>0.413333</td>\n      <td>0.446667</td>\n      <td>0.560000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.114286</td>\n      <td>0.485000</td>\n      <td>0.435000</td>\n      <td>0.503333</td>\n      <td>0.500000</td>\n      <td>0.450000</td>\n      <td>0.430000</td>\n      <td>0.390000</td>\n      <td>0.300000</td>\n      <td>0.490000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.114286</td>\n      <td>0.491667</td>\n      <td>0.465000</td>\n      <td>0.473333</td>\n      <td>0.466667</td>\n      <td>0.438333</td>\n      <td>0.406667</td>\n      <td>0.370000</td>\n      <td>0.411667</td>\n      <td>0.488333</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>0.114286</td>\n      <td>0.458333</td>\n      <td>0.400000</td>\n      <td>0.440000</td>\n      <td>0.458333</td>\n      <td>0.430000</td>\n      <td>0.410000</td>\n      <td>0.398333</td>\n      <td>0.300000</td>\n      <td>0.440000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.125</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>869672092/2020</th>\n      <td>0.171429</td>\n      <td>0.383333</td>\n      <td>0.421667</td>\n      <td>0.428333</td>\n      <td>0.465000</td>\n      <td>0.435000</td>\n      <td>0.421667</td>\n      <td>0.361667</td>\n      <td>0.510000</td>\n      <td>0.455000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.000</td>\n      <td>0.222222</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>995492008/2020</th>\n      <td>0.171429</td>\n      <td>0.360000</td>\n      <td>0.400000</td>\n      <td>0.430000</td>\n      <td>0.470000</td>\n      <td>0.435000</td>\n      <td>0.426667</td>\n      <td>0.368333</td>\n      <td>0.515000</td>\n      <td>0.445000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.000</td>\n      <td>0.222222</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>914335027/2020</th>\n      <td>0.109524</td>\n      <td>0.495000</td>\n      <td>0.518333</td>\n      <td>0.506667</td>\n      <td>0.476667</td>\n      <td>0.435000</td>\n      <td>0.421667</td>\n      <td>0.448333</td>\n      <td>0.558333</td>\n      <td>0.540000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.222222</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>997795016/2020</th>\n      <td>0.171429</td>\n      <td>0.445000</td>\n      <td>0.515000</td>\n      <td>0.485000</td>\n      <td>0.468333</td>\n      <td>0.406667</td>\n      <td>0.410000</td>\n      <td>0.408333</td>\n      <td>0.496667</td>\n      <td>0.510000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.222222</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>968956779/2020</th>\n      <td>0.380952</td>\n      <td>0.273333</td>\n      <td>0.358333</td>\n      <td>0.428333</td>\n      <td>0.446667</td>\n      <td>0.385000</td>\n      <td>0.453333</td>\n      <td>0.436667</td>\n      <td>0.475000</td>\n      <td>0.508333</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.250</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n    </tr>\n  </tbody>\n</table>\n<p>41027 rows × 1502 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunlight_data = get_interpolated_data(years, 'sunlight')\n",
    "daydegree5_data = get_interpolated_data(years, 'daydegree5').drop(columns=['longitude', 'latitude', 'elevation'])\n",
    "ground_data = get_proximity_data(years, 'ground')\n",
    "temp_and_precip_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "weather_data = temp_and_precip_data.merge(sunlight_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(daydegree5_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(ground_data, how='left', on=['orgnr', 'year'])\n",
    "\n",
    "print(f\"Merged {temp_and_precip_data.shape[1]} features of temp and precip data, {sunlight_data.shape[1]} features of sunlight data, {daydegree5_data.shape[1]} features of daydegree data, {ground_data.shape[1]} features of ground data to a total of {weather_data.shape[1]} features\")\n",
    "\n",
    "#weather_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "\n",
    "weather_data[\"key\"] = weather_data.orgnr.astype(int).astype(str) + \"/\" + weather_data.year.astype(int).astype(str)\n",
    "weather_data.drop(columns=[\"year\", \"orgnr\"], inplace=True)\n",
    "weather_data = weather_data.drop_duplicates(subset=[\"key\"])\n",
    "weather_data = weather_data.set_index(\"key\")\n",
    "weather_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Combine dataset\n",
    "\n",
    "# sat_img_path = 'C:/'\n",
    "# from sentinel.storage import SentinelDataset\n",
    "# print(\"Reading sentinel_100x100_0.h5\")\n",
    "# ds0 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_0.h5\")\n",
    "# print(\"Reading sentinel_100x100_1.h5\")\n",
    "# ds1 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_1.h5\")\n",
    "# print(\"Combining both\")\n",
    "# SentinelDataset.combine_datasets([ds0, ds1], \"E:/combined_compressed.h5\", compression=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13597/13597 [00:07<00:00, 1928.42it/s]\n",
      "100%|██████████| 13582/13582 [00:00<00:00, 29030.27it/s]\n",
      "100%|██████████| 12876/12876 [00:12<00:00, 1052.11it/s]\n",
      "100%|██████████| 3400/3400 [00:01<00:00, 2304.84it/s]\n",
      "100%|██████████| 3395/3395 [00:00<00:00, 31299.88it/s]\n",
      "100%|██████████| 3182/3182 [00:03<00:00, 1053.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from kornmo.sentinel.storage import SentinelDataset\n",
    "sat_img_path = 'E:/MasterThesisData/Satellite_Images'\n",
    "#sat_img_path = 'C:/'\n",
    "sd = SentinelDataset(f\"{sat_img_path}/combined_uncompressed.h5\")\n",
    "train, val = sd.to_iterator().split(rand_seed='abc')\n",
    "\n",
    "def add_historical(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" in historical.index.values:\n",
    "        h_data = historical.loc[f\"{orgnr}/{year}\"]\n",
    "        return {'historical': h_data.values }\n",
    "    else:\n",
    "        return []\n",
    "def add_weather(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" not in weather_data.index:\n",
    "        return []\n",
    "    wd = weather_data.loc[f\"{orgnr}/{year}\"]\n",
    "    # min_temps = [value for key, value in wd.items() if key.startswith(\"min_temp\")]\n",
    "    # mean_temps = [value for key, value in wd.items() if key.startswith(\"mean_temp\")]\n",
    "    # max_temps = [value for key, value in wd.items() if key.startswith(\"max_temp\")]\n",
    "    # total_rain = [value for key, value in wd.items() if key.startswith(\"total_rain\")]\n",
    "    # stacked = np.stack((min_temps, mean_temps, max_temps, total_rain), axis=1)\n",
    "\n",
    "    return { 'weather': wd.values }\n",
    "\n",
    "def add_grain_types(orgnr, year, data):\n",
    "    samples = deliveries.loc[[f\"{orgnr}/{year}\"]]\n",
    "\n",
    "    all_grains = []\n",
    "    for _, row in samples.iterrows():\n",
    "        sample = {}\n",
    "        if row.bygg: sample[\"type\"] = (1,0,0,0)\n",
    "        elif row.havre: sample[\"type\"] = (0,1,0,0)\n",
    "        elif row.rug_og_rughvete: sample[\"type\"] = (0,0,1,0)\n",
    "        elif row.hvete: sample[\"type\"] = (0,0,0,1)\n",
    "\n",
    "        sample[\"areal\"] = row[\"areal\"]\n",
    "        sample[\"lat\"] = row[\"lat\"]\n",
    "        sample[\"elevation\"] = row[\"elevation\"]\n",
    "        sample[\"yield\"] = row[\"yield\"]\n",
    "        sample['fulldyrket'] = row['fulldyrket']\n",
    "        sample['overflatedyrket'] = row['overflatedyrket']\n",
    "        sample['tilskudd_dyr'] = row['tilskudd_dyr']\n",
    "        all_grains.append(sample)\n",
    "\n",
    "    return all_grains\n",
    "\n",
    "train = train.with_data(add_historical, True)\\\n",
    "             .with_data(add_weather, True)\\\n",
    "             .with_data(add_grain_types, True)\n",
    "\n",
    "val = val.with_data(add_historical, True)\\\n",
    "         .with_data(add_weather, True)\\\n",
    "         .with_data(add_grain_types, True)\n",
    "\n",
    "#13597\n",
    "#13582\n",
    "#12876\n",
    "#3400\n",
    "#3395\n",
    "#3182"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['2017', '2018', '2019']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('data/masks/nibio_disposed_properties_masks.h5', \"r+\") as out_file:\n",
    "    print(out_file['masks']['811555762'].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 19003\n",
      "val samples: 4706\n"
     ]
    }
   ],
   "source": [
    "from kornmo.mask.mask_dataset import MaskDataset\n",
    "from kornmo.mask.utils import add_mask_as_channel, apply_mask_to_image_series\n",
    "\n",
    "mask_dataset_path = \"data/masks/nibio_disposed_properties_masks.h5\"\n",
    "mask_dataset = MaskDataset(mask_dataset_path)\n",
    "#print(mask_dataset.labels)\n",
    "\n",
    "mask_iterator = mask_dataset.get_iterator()\n",
    "mask_dict = {}\n",
    "for orgnr, year, mask in mask_iterator:\n",
    "    mask_dict[f'{orgnr}/{year}'] = mask\n",
    "\n",
    "def apply_mask(orgnr, year, imgs):\n",
    "    mask = mask_dict[f'{orgnr}/{year}']\n",
    "    return apply_mask_to_image_series(mask, imgs)\n",
    "\n",
    "train = train.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "val = val.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "\n",
    "print(f\"train samples: {len(train)}\")\n",
    "print(f\"val samples: {len(val)}\")\n",
    "#19003\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented samples: 95015\n",
      "Validation samples: 4706\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.data.experimental import assert_cardinality\n",
    "from kornmo.sentinel.transform import salt_n_pepper, rotate180, rotate90\n",
    "\n",
    "stride = 10\n",
    "def top_left(imgs):\n",
    "    return imgs[...,:-stride, :-stride,:]\n",
    "def top_right(imgs):\n",
    "    return imgs[...,:-stride, stride:,:]\n",
    "def bot_left(imgs):\n",
    "    return imgs[...,stride:, :-stride,:]\n",
    "def bot_right(imgs):\n",
    "    return imgs[...,stride:, stride:,:]\n",
    "def center(imgs):\n",
    "    s = stride//2\n",
    "    return imgs[...,s:-s, s:-s,:]\n",
    "\n",
    "def rotate_random(imgs):\n",
    "    angle = np.random.rand(30) * 6.28\n",
    "    return tfa.image.rotate(imgs, angle)\n",
    "\n",
    "augmented_dataset = train\\\n",
    "    .transform(apply_mask)\\\n",
    "    .transform(salt_n_pepper())\\\n",
    "    .augment([center, top_left, top_right, bot_left, bot_right], keep_original=False)\\\n",
    "    .transform(rotate_random)\n",
    "\n",
    "def apply_output(orgnr, year, img_source, data):\n",
    "    features = data[\"areal\"], *data[\"type\"]\n",
    "    output = data[\"yield\"]\n",
    "    weather = data[\"weather\"][1:]\n",
    "    return {\"cnn_input\": img_source[0:30], \"feature_input\": features, \"weather_input\": weather}, output\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    augmented_dataset.apply(apply_output).shuffled(),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(assert_cardinality(len(augmented_dataset)))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val.transform(apply_mask).transform(center).apply(apply_output),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(assert_cardinality(len(val)))\n",
    "\n",
    "print(f\"Augmented samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "#95015\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0epoch [00:00, ?epoch/s]\n",
      "  0%|          | 0/10 [00:00<?, ?epoch/s]\n",
      "  0%|          | 0.00/313 [00:00<?, ?batch/s]\u001B[A\n",
      "  0%|          | 1.00/313 [00:14<1:13:07, 14.1s/batch, loss=0.196]\u001B[A\n",
      "  1%|          | 2.00/313 [00:14<30:50, 5.95s/batch, loss=0.471]  \u001B[A\n",
      "  1%|          | 3.00/313 [00:18<26:10, 5.06s/batch, loss=0.436]\u001B[A\n",
      "  1%|▏         | 4.00/313 [00:22<24:04, 4.67s/batch, loss=0.469]\u001B[A\n",
      "  2%|▏         | 5.00/313 [00:26<23:09, 4.51s/batch, loss=0.425]\u001B[A\n",
      "  2%|▏         | 6.00/313 [00:31<23:30, 4.60s/batch, loss=0.4]  \u001B[A\n",
      "  2%|▏         | 7.00/313 [00:35<23:11, 4.55s/batch, loss=0.385]\u001B[A\n",
      "  3%|▎         | 8.00/313 [00:40<22:54, 4.50s/batch, loss=0.355]\u001B[A\n",
      "  3%|▎         | 9.00/313 [00:44<22:30, 4.44s/batch, loss=0.342]\u001B[A\n",
      "  3%|▎         | 10.0/313 [00:48<22:06, 4.38s/batch, loss=0.326]\u001B[A\n",
      "  4%|▎         | 11.0/313 [00:53<21:47, 4.33s/batch, loss=0.312]\u001B[A\n",
      "  4%|▍         | 12.0/313 [00:57<21:40, 4.32s/batch, loss=0.297]\u001B[A\n",
      "  4%|▍         | 13.0/313 [01:01<21:34, 4.32s/batch, loss=0.288]\u001B[A\n",
      "  4%|▍         | 14.0/313 [01:05<21:31, 4.32s/batch, loss=0.285]\u001B[A\n",
      "  5%|▍         | 15.0/313 [01:10<21:19, 4.29s/batch, loss=0.273]\u001B[A\n",
      "  5%|▌         | 16.0/313 [01:14<21:03, 4.26s/batch, loss=0.268]\u001B[A\n",
      "  5%|▌         | 17.0/313 [01:18<21:02, 4.27s/batch, loss=0.264]\u001B[A\n",
      "  6%|▌         | 18.0/313 [01:23<21:41, 4.41s/batch, loss=0.257]\u001B[A\n",
      "  6%|▌         | 19.0/313 [01:28<21:57, 4.48s/batch, loss=0.251]\u001B[A\n",
      "  6%|▋         | 20.0/313 [01:32<21:40, 4.44s/batch, loss=0.245]\u001B[A\n",
      "  7%|▋         | 21.0/313 [01:36<21:23, 4.40s/batch, loss=0.24] \u001B[A\n",
      "  7%|▋         | 22.0/313 [01:40<21:11, 4.37s/batch, loss=0.235]\u001B[A\n",
      "  7%|▋         | 23.0/313 [01:45<21:16, 4.40s/batch, loss=0.231]\u001B[A\n",
      "  8%|▊         | 24.0/313 [01:50<21:25, 4.45s/batch, loss=0.227]\u001B[A\n",
      "  8%|▊         | 25.0/313 [01:54<21:29, 4.48s/batch, loss=0.224]\u001B[A\n",
      "  8%|▊         | 26.0/313 [01:59<21:22, 4.47s/batch, loss=0.221]\u001B[A\n",
      "  9%|▊         | 27.0/313 [02:03<21:39, 4.55s/batch, loss=0.218]\u001B[A\n",
      "  9%|▉         | 28.0/313 [02:08<21:17, 4.48s/batch, loss=0.214]\u001B[A\n",
      "  9%|▉         | 29.0/313 [02:12<21:25, 4.53s/batch, loss=0.21] \u001B[A\n",
      " 10%|▉         | 30.0/313 [02:17<21:12, 4.50s/batch, loss=0.209]\u001B[A\n",
      " 10%|▉         | 31.0/313 [02:21<21:03, 4.48s/batch, loss=0.206]\u001B[A\n",
      " 10%|█         | 32.0/313 [02:26<21:09, 4.52s/batch, loss=0.204]\u001B[A\n",
      " 11%|█         | 33.0/313 [02:30<21:21, 4.58s/batch, loss=0.201]\u001B[A\n",
      " 11%|█         | 34.0/313 [02:35<21:16, 4.58s/batch, loss=0.199]\u001B[A\n",
      " 11%|█         | 35.0/313 [02:40<21:09, 4.57s/batch, loss=0.196]\u001B[A\n",
      " 12%|█▏        | 36.0/313 [02:44<21:14, 4.60s/batch, loss=0.194]\u001B[A\n",
      " 12%|█▏        | 37.0/313 [02:49<21:02, 4.58s/batch, loss=0.194]\u001B[A\n",
      " 12%|█▏        | 38.0/313 [02:54<21:17, 4.65s/batch, loss=0.191]\u001B[A\n",
      " 12%|█▏        | 39.0/313 [02:58<20:58, 4.59s/batch, loss=0.19] \u001B[A\n",
      " 13%|█▎        | 40.0/313 [03:02<20:12, 4.44s/batch, loss=0.188]\u001B[A\n",
      " 13%|█▎        | 41.0/313 [03:06<19:59, 4.41s/batch, loss=0.186]\u001B[A\n",
      " 13%|█▎        | 42.0/313 [03:11<19:32, 4.33s/batch, loss=0.185]\u001B[A\n",
      " 14%|█▎        | 43.0/313 [03:15<19:30, 4.33s/batch, loss=0.185]\u001B[A\n",
      " 14%|█▍        | 44.0/313 [03:19<19:08, 4.27s/batch, loss=0.183]\u001B[A\n",
      " 14%|█▍        | 45.0/313 [03:24<19:23, 4.34s/batch, loss=0.182]\u001B[A\n",
      " 15%|█▍        | 46.0/313 [03:28<19:14, 4.33s/batch, loss=0.18] \u001B[A\n",
      " 15%|█▌        | 47.0/313 [03:32<19:11, 4.33s/batch, loss=0.179]\u001B[A\n",
      " 15%|█▌        | 48.0/313 [03:36<18:29, 4.19s/batch, loss=0.178]\u001B[A\n",
      " 16%|█▌        | 49.0/313 [03:40<18:42, 4.25s/batch, loss=0.176]\u001B[A\n",
      " 16%|█▌        | 50.0/313 [03:45<18:46, 4.28s/batch, loss=0.175]\u001B[A\n",
      " 16%|█▋        | 51.0/313 [03:49<18:25, 4.22s/batch, loss=0.174]\u001B[A\n",
      " 17%|█▋        | 52.0/313 [03:54<19:33, 4.50s/batch, loss=0.174]\u001B[A\n",
      " 17%|█▋        | 53.0/313 [03:58<19:29, 4.50s/batch, loss=0.173]\u001B[A\n",
      " 17%|█▋        | 54.0/313 [04:03<18:56, 4.39s/batch, loss=0.173]\u001B[A\n",
      " 18%|█▊        | 55.0/313 [04:08<20:06, 4.68s/batch, loss=0.172]\u001B[A\n",
      " 18%|█▊        | 56.0/313 [04:13<20:38, 4.82s/batch, loss=0.171]\u001B[A\n",
      " 18%|█▊        | 57.0/313 [04:18<20:04, 4.70s/batch, loss=0.171]\u001B[A\n",
      " 19%|█▊        | 58.0/313 [04:23<20:27, 4.81s/batch, loss=0.17] \u001B[A\n",
      " 19%|█▉        | 59.0/313 [04:27<20:09, 4.76s/batch, loss=0.169]\u001B[A\n",
      " 19%|█▉        | 60.0/313 [04:32<20:18, 4.82s/batch, loss=0.168]\u001B[A\n",
      " 19%|█▉        | 61.0/313 [04:36<19:26, 4.63s/batch, loss=0.167]\u001B[A\n",
      " 20%|█▉        | 62.0/313 [04:41<19:55, 4.76s/batch, loss=0.166]\u001B[A\n",
      " 20%|██        | 63.0/313 [04:47<20:51, 5.01s/batch, loss=0.166]\u001B[A\n",
      " 20%|██        | 64.0/313 [04:52<20:41, 4.98s/batch, loss=0.166]\u001B[A\n",
      " 21%|██        | 65.0/313 [04:57<20:49, 5.04s/batch, loss=0.165]\u001B[A\n",
      " 21%|██        | 66.0/313 [05:02<20:23, 4.95s/batch, loss=0.165]\u001B[A\n",
      " 21%|██▏       | 67.0/313 [05:07<20:17, 4.95s/batch, loss=0.164]\u001B[A\n",
      " 22%|██▏       | 68.0/313 [05:12<20:11, 4.95s/batch, loss=0.163]\u001B[A\n",
      " 22%|██▏       | 69.0/313 [05:17<20:20, 5.00s/batch, loss=0.163]\u001B[A\n",
      " 22%|██▏       | 70.0/313 [05:22<19:59, 4.94s/batch, loss=0.162]\u001B[A\n",
      " 23%|██▎       | 71.0/313 [05:26<19:33, 4.85s/batch, loss=0.162]\u001B[A\n",
      " 23%|██▎       | 72.0/313 [05:31<18:57, 4.72s/batch, loss=0.162]\u001B[A\n",
      " 23%|██▎       | 73.0/313 [05:35<17:56, 4.48s/batch, loss=0.162]\u001B[A\n",
      " 24%|██▎       | 74.0/313 [05:39<18:01, 4.53s/batch, loss=0.161]\u001B[A\n",
      " 24%|██▍       | 75.0/313 [05:44<17:44, 4.47s/batch, loss=0.161]\u001B[A\n",
      " 24%|██▍       | 76.0/313 [05:48<17:48, 4.51s/batch, loss=0.161]\u001B[A\n",
      " 25%|██▍       | 77.0/313 [05:53<17:43, 4.50s/batch, loss=0.16] \u001B[A\n",
      " 25%|██▍       | 78.0/313 [05:58<18:07, 4.63s/batch, loss=0.159]\u001B[A\n",
      " 25%|██▌       | 79.0/313 [06:02<17:59, 4.61s/batch, loss=0.159]\u001B[A\n",
      " 26%|██▌       | 80.0/313 [06:07<17:32, 4.52s/batch, loss=0.159]\u001B[A\n",
      " 26%|██▌       | 81.0/313 [06:11<17:36, 4.56s/batch, loss=0.158]\u001B[A\n",
      " 26%|██▌       | 82.0/313 [06:16<17:55, 4.66s/batch, loss=0.158]\u001B[A\n",
      " 27%|██▋       | 83.0/313 [06:21<17:58, 4.69s/batch, loss=0.157]\u001B[A\n",
      " 27%|██▋       | 84.0/313 [06:25<17:26, 4.57s/batch, loss=0.157]\u001B[A\n",
      " 27%|██▋       | 85.0/313 [06:29<16:52, 4.44s/batch, loss=0.157]\u001B[A\n",
      " 27%|██▋       | 86.0/313 [06:34<16:42, 4.41s/batch, loss=0.156]\u001B[A\n",
      " 28%|██▊       | 87.0/313 [06:39<17:20, 4.60s/batch, loss=0.156]\u001B[A\n",
      " 28%|██▊       | 88.0/313 [06:43<17:23, 4.64s/batch, loss=0.155]\u001B[A\n",
      " 28%|██▊       | 89.0/313 [06:48<17:32, 4.70s/batch, loss=0.155]\u001B[A\n",
      " 29%|██▉       | 90.0/313 [06:53<17:27, 4.70s/batch, loss=0.154]\u001B[A\n",
      " 29%|██▉       | 91.0/313 [06:57<16:50, 4.55s/batch, loss=0.154]\u001B[A\n",
      " 29%|██▉       | 92.0/313 [07:02<17:00, 4.62s/batch, loss=0.153]\u001B[A\n",
      " 30%|██▉       | 93.0/313 [07:07<17:03, 4.65s/batch, loss=0.153]\u001B[A\n",
      " 30%|███       | 94.0/313 [07:11<16:48, 4.60s/batch, loss=0.152]\u001B[A\n",
      " 30%|███       | 95.0/313 [07:15<16:25, 4.52s/batch, loss=0.152]\u001B[A\n",
      " 31%|███       | 96.0/313 [07:20<16:28, 4.56s/batch, loss=0.151]\u001B[A\n",
      " 31%|███       | 97.0/313 [07:24<15:32, 4.32s/batch, loss=0.151]\u001B[A\n",
      " 31%|███▏      | 98.0/313 [07:28<15:22, 4.29s/batch, loss=0.151]\u001B[A\n",
      " 32%|███▏      | 99.0/313 [07:32<15:21, 4.30s/batch, loss=0.151]\u001B[A\n",
      " 32%|███▏      | 100/313 [07:36<14:56, 4.21s/batch, loss=0.15]  \u001B[A\n",
      " 32%|███▏      | 101/313 [07:40<14:43, 4.17s/batch, loss=0.15]\u001B[A\n",
      " 33%|███▎      | 102/313 [07:44<14:20, 4.08s/batch, loss=0.15]\u001B[A\n",
      " 33%|███▎      | 103/313 [07:49<14:25, 4.12s/batch, loss=0.15]\u001B[A\n",
      " 33%|███▎      | 104/313 [07:53<14:12, 4.08s/batch, loss=0.149]\u001B[A\n",
      " 34%|███▎      | 105/313 [07:57<14:12, 4.10s/batch, loss=0.149]\u001B[A\n",
      " 34%|███▍      | 106/313 [08:01<14:25, 4.18s/batch, loss=0.149]\u001B[A\n",
      " 34%|███▍      | 107/313 [08:05<14:34, 4.25s/batch, loss=0.148]\u001B[A\n",
      " 35%|███▍      | 108/313 [08:10<14:44, 4.31s/batch, loss=0.148]\u001B[A\n",
      " 35%|███▍      | 109/313 [08:14<14:24, 4.24s/batch, loss=0.148]\u001B[A\n",
      " 35%|███▌      | 110/313 [08:18<14:28, 4.28s/batch, loss=0.148]\u001B[A\n",
      " 35%|███▌      | 111/313 [08:23<14:23, 4.27s/batch, loss=0.147]\u001B[A\n",
      " 36%|███▌      | 112/313 [08:27<14:20, 4.28s/batch, loss=0.147]\u001B[A\n",
      " 36%|███▌      | 113/313 [08:31<14:29, 4.35s/batch, loss=0.147]\u001B[A\n",
      " 36%|███▋      | 114/313 [08:36<14:19, 4.32s/batch, loss=0.147]\u001B[A\n",
      " 37%|███▋      | 115/313 [08:40<14:23, 4.36s/batch, loss=0.146]\u001B[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_24560/1766930067.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcallback\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mTqdmCallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtqdm_class\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m     cnn_history = cnn.fit(\n\u001B[0m\u001B[0;32m     62\u001B[0m         \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprefetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprefetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "def CNN(input_dim, output_dim):\n",
    "    input_layer = layers.Input(shape=input_dim)\n",
    "    y = layers.Conv2D(16, (3, 3), activation=tf.nn.relu, padding='same')(input_layer)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(output_dim, activation=tf.nn.relu)(y)\n",
    "\n",
    "    return models.Model(inputs=[input_layer], outputs=[y], name=\"SingleImageCNN\")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    './training',\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "callbacks = [callback, model_checkpoint]\n",
    "\n",
    "restart = True\n",
    "if restart:\n",
    "\n",
    "    scnn = CNN((90, 90, 12), 64)\n",
    "    #scnn.summary(line_length=130)\n",
    "    input_weather = layers.Input(shape=1501, name=\"weather_input\") #shape = 856 / 1501\n",
    "    t_wm = layers.Reshape((19, 79))(input_weather) # (4, 214) / (19, 79)\n",
    "    t_wm = layers.Permute((2, 1))(t_wm)\n",
    "    t_wm = layers.Conv1D(64, 50, activation=tf.nn.relu)(t_wm) # (64, 7, 7) / (64, 50)\n",
    "\n",
    "    input_cnn = layers.Input(shape=(30, 90, 90, 12), name=\"cnn_input\")\n",
    "\n",
    "    feature_input = layers.Input(shape=(5,), name=\"feature_input\")\n",
    "    feature_repeated = layers.RepeatVector(30)(feature_input)\n",
    "\n",
    "    cnn = layers.TimeDistributed(scnn)(input_cnn)\n",
    "    cnn = layers.Concatenate(axis=2)([cnn, feature_repeated, t_wm])\n",
    "    cnn = layers.GRU(128, return_sequences=False)(cnn)\n",
    "    cnn = layers.Flatten()(cnn)\n",
    "    cnn = layers.Dense(128, activation=tf.nn.relu)(cnn)\n",
    "    cnn = layers.Dense(1)(cnn)\n",
    "\n",
    "    cnn = models.Model(inputs=[input_weather, input_cnn, feature_input], outputs=cnn, name=\"CNN\")\n",
    "    #cnn.summary(line_length=130)\n",
    "\n",
    "    cnn.compile(optimizer=optimizers.Adam(), loss='mean_absolute_error')\n",
    "\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "else:\n",
    "    cnn = load_model('./training/epoch_2.hdf5')\n",
    "    # update the learning rate\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = pd.read_json('training/hybrid_more_features.json')\n",
    "history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(history['loss'].tolist(), label=\"loss\")\n",
    "plt.plot(history['val_loss'].tolist(), label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Mean absolute error loss\")\n",
    "plt.savefig('logs/hybrid_more_features.svg', dpi=600)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}