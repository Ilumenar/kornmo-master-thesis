{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from kornmo import KornmoDataset\n",
    "from geodata import get_farmer_elevation\n",
    "import kornmo_utils as ku\n",
    "from frostdataset import FrostDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def filter_by_years(years, data):\n",
    "    return data[data['year'].isin(years)]\n",
    "\n",
    "def get_interpolated_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/nn_interpolated/{weather_feature}/{weather_feature}_interpolated_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    # Drop columns containing 'Unnamed'\n",
    "    data.drop(columns=[col for col in data.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year', 'longitude', 'latitude', 'elevation']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_proximity_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/by_proximity/{weather_feature}/{weather_feature}_by_proximity_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.drop(columns=['ws_id'], inplace=True)\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deliveries...\n",
      "Number of deliveries loaded: 88624\n"
     ]
    },
    {
     "data": {
      "text/plain": "                year      orgnr  kommunenr  gaardsnummer  bruksnummer  \\\nkey                                                                     \n811555762/2017  2017  811555762       1653            24            2   \n811580082/2017  2017  811580082       1124            25            5   \n811675792/2017  2017  811675792        709          2023           12   \n811675792/2017  2017  811675792        709          2023           12   \n811935662/2017  2017  811935662        125           207            1   \n...              ...        ...        ...           ...          ...   \n999659209/2020  2020  999659209       3812            31           64   \n999662730/2020  2020  999662730       3802           247            1   \n999662730/2020  2020  999662730       3802           247            1   \n999665462/2020  2020  999665462       3028            69            1   \n999666248/2020  2020  999666248       3030           252           10   \n\n                festenummer  fulldyrket  overflatedyrket  tilskudd_dyr  \\\nkey                                                                      \n811555762/2017            0    0.007241              0.0      0.000000   \n811580082/2017            0    0.110575              0.0      0.335581   \n811675792/2017            0    0.014180              0.0      0.000000   \n811675792/2017            0    0.014180              0.0      0.000000   \n811935662/2017            0    0.014331              0.0      0.000000   \n...                     ...         ...              ...           ...   \n999659209/2020            0    0.007543              0.0      0.000000   \n999662730/2020            0    0.043898              0.0      0.000000   \n999662730/2020            0    0.043898              0.0      0.000000   \n999665462/2020            0    0.039674              0.0      0.052484   \n999666248/2020            0    0.022477              0.0      0.000000   \n\n                levert     areal  bygg  havre  hvete  rug_og_rughvete  \\\nkey                                                                     \n811555762/2017   17067  0.017475   1.0    0.0    0.0              0.0   \n811580082/2017   81204  0.064477   1.0    0.0    0.0              0.0   \n811675792/2017   10902  0.020789   1.0    0.0    0.0              0.0   \n811675792/2017    2335  0.004218   0.0    0.0    1.0              0.0   \n811935662/2017   33166  0.031636   0.0    0.0    1.0              0.0   \n...                ...       ...   ...    ...    ...              ...   \n999659209/2020   32209  0.018078   0.0    0.0    0.0              1.0   \n999662730/2020  100087  0.065080   0.0    1.0    0.0              0.0   \n999662730/2020   39067  0.023802   0.0    0.0    1.0              0.0   \n999665462/2020   38686  0.034348   0.0    1.0    0.0              0.0   \n999666248/2020  100663  0.047906   0.0    1.0    0.0              0.0   \n\n                     lat  elevation     yield  \nkey                                            \n811555762/2017  0.959116   0.051198  0.289271  \n811580082/2017  0.891830   0.024510  0.377693  \n811675792/2017  0.896483   0.014706  0.155743  \n811675792/2017  0.896483   0.014706  0.155667  \n811935662/2017  0.907412   0.073529  0.312887  \n...                  ...        ...       ...  \n999659209/2020  0.898225   0.068627  0.528016  \n999662730/2020  0.902149   0.093137  0.461230  \n999662730/2020  0.902149   0.093137  0.488337  \n999665462/2020  0.905165   0.142157  0.336400  \n999666248/2020  0.909951   0.132353  0.629144  \n\n[60462 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>orgnr</th>\n      <th>kommunenr</th>\n      <th>gaardsnummer</th>\n      <th>bruksnummer</th>\n      <th>festenummer</th>\n      <th>fulldyrket</th>\n      <th>overflatedyrket</th>\n      <th>tilskudd_dyr</th>\n      <th>levert</th>\n      <th>areal</th>\n      <th>bygg</th>\n      <th>havre</th>\n      <th>hvete</th>\n      <th>rug_og_rughvete</th>\n      <th>lat</th>\n      <th>elevation</th>\n      <th>yield</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>2017</td>\n      <td>811555762</td>\n      <td>1653</td>\n      <td>24</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.007241</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>17067</td>\n      <td>0.017475</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.959116</td>\n      <td>0.051198</td>\n      <td>0.289271</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2017</td>\n      <td>811580082</td>\n      <td>1124</td>\n      <td>25</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.110575</td>\n      <td>0.0</td>\n      <td>0.335581</td>\n      <td>81204</td>\n      <td>0.064477</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.891830</td>\n      <td>0.024510</td>\n      <td>0.377693</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.014180</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>10902</td>\n      <td>0.020789</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155743</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>2017</td>\n      <td>811675792</td>\n      <td>709</td>\n      <td>2023</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.014180</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2335</td>\n      <td>0.004218</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.896483</td>\n      <td>0.014706</td>\n      <td>0.155667</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>2017</td>\n      <td>811935662</td>\n      <td>125</td>\n      <td>207</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.014331</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>33166</td>\n      <td>0.031636</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.907412</td>\n      <td>0.073529</td>\n      <td>0.312887</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999659209/2020</th>\n      <td>2020</td>\n      <td>999659209</td>\n      <td>3812</td>\n      <td>31</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0.007543</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>32209</td>\n      <td>0.018078</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.898225</td>\n      <td>0.068627</td>\n      <td>0.528016</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>2020</td>\n      <td>999662730</td>\n      <td>3802</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.043898</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>100087</td>\n      <td>0.065080</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.461230</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>2020</td>\n      <td>999662730</td>\n      <td>3802</td>\n      <td>247</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.043898</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>39067</td>\n      <td>0.023802</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.902149</td>\n      <td>0.093137</td>\n      <td>0.488337</td>\n    </tr>\n    <tr>\n      <th>999665462/2020</th>\n      <td>2020</td>\n      <td>999665462</td>\n      <td>3028</td>\n      <td>69</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.039674</td>\n      <td>0.0</td>\n      <td>0.052484</td>\n      <td>38686</td>\n      <td>0.034348</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.905165</td>\n      <td>0.142157</td>\n      <td>0.336400</td>\n    </tr>\n    <tr>\n      <th>999666248/2020</th>\n      <td>2020</td>\n      <td>999666248</td>\n      <td>3030</td>\n      <td>252</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.022477</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>100663</td>\n      <td>0.047906</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.909951</td>\n      <td>0.132353</td>\n      <td>0.629144</td>\n    </tr>\n  </tbody>\n</table>\n<p>60462 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [2017, 2018, 2019, 2020]\n",
    "frost = FrostDataset()\n",
    "kornmo = KornmoDataset()\n",
    "deliveries = kornmo.get_deliveries().pipe(ku.split_farmers_on_type)\n",
    "\n",
    "elevation_data = get_farmer_elevation()\n",
    "deliveries = deliveries.merge(elevation_data, on=['orgnr'], how='left').fillna(0)\n",
    "\n",
    "deliveries[\"yield\"] = ku.normalize(deliveries[\"levert\"]/deliveries[\"areal\"], 0, 1000)\n",
    "deliveries[\"areal\"] = ku.normalize(deliveries[\"areal\"])\n",
    "deliveries['fulldyrket'] = ku.normalize(deliveries['fulldyrket'])\n",
    "deliveries['overflatedyrket'] = ku.normalize(deliveries['overflatedyrket'])\n",
    "deliveries['tilskudd_dyr'] = ku.normalize(deliveries['tilskudd_dyr'])\n",
    "deliveries['lat'] = ku.normalize(deliveries['lat'])\n",
    "deliveries['elevation'] = ku.normalize(deliveries['elevation'])\n",
    "\n",
    "deliveries[\"key\"] = deliveries.orgnr.astype(str) + \"/\" + deliveries.year.astype(str)\n",
    "deliveries = deliveries.set_index(\"key\")\n",
    "deliveries = filter_by_years(years, deliveries)\n",
    "\n",
    "deliveries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical grants data...\n",
      "Historical data loaded for years 2013 to 2020.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                bygg_sum_0  hvete_sum_0  havre_sum_0  rug_og_rughvete_sum_0  \\\nkey                                                                           \n811555762/2017      1.3687       0.0000       0.0000                    0.0   \n811580082/2017      2.9200       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       0.0000       0.0000                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7688       0.4413       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020     14.6406       0.0000       4.8990                    0.0   \n999659209/2020      1.8102       0.0000       0.0000                    0.0   \n999662730/2020      0.0000       2.9122      10.4515                    0.0   \n999665462/2020      0.0000       0.0000       0.0000                    0.0   \n999666248/2020      0.0000       0.0000       9.8484                    0.0   \n\n                bygg_sum_1  hvete_sum_1  havre_sum_1  rug_og_rughvete_sum_1  \\\nkey                                                                           \n811555762/2017      2.2050       0.0000       0.0000                    0.0   \n811580082/2017      4.7596       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       2.8870       0.6015                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      3.3676       0.0000       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020      9.4914      33.1335       5.0059                    0.0   \n999659209/2020      0.0000       1.1576       0.0000                    0.0   \n999662730/2020      0.0000       4.7917       8.2873                    0.0   \n999665462/2020      0.0000       0.0000       2.1122                    0.0   \n999666248/2020      0.0000       0.0000       8.5110                    0.0   \n\n                bygg_sum_2  hvete_sum_2  havre_sum_2  rug_og_rughvete_sum_2  \\\nkey                                                                           \n811555762/2017      2.0620       0.0000       0.0000                    0.0   \n811580082/2017      6.4999       0.0000       0.0000                    0.0   \n811675792/2017      0.0000       1.4844       0.2770                    0.0   \n811935662/2017      0.0000       0.0000       0.0000                    0.0   \n812075322/2017      1.7060       1.4768       0.0000                    0.0   \n...                    ...          ...          ...                    ...   \n999640001/2020      8.4269       6.3109       0.0000                    0.0   \n999659209/2020      0.0000       0.0000       1.5396                    0.0   \n999662730/2020      0.0000       1.8919       5.8078                    0.0   \n999665462/2020      0.0000       0.0000       0.6108                    0.0   \n999666248/2020      3.8498       0.0000       0.0000                    0.0   \n\n                bygg_sum_3  hvete_sum_3  havre_sum_3  rug_og_rughvete_sum_3  \nkey                                                                          \n811555762/2017      2.2445       0.0000       0.0000                    0.0  \n811580082/2017     11.7227       0.0000       0.0000                    0.0  \n811675792/2017      0.0000       2.2717       0.4869                    0.0  \n811935662/2017      1.0643       2.5620       0.0000                    0.0  \n812075322/2017      2.2838       1.0750       0.0000                    0.0  \n...                    ...          ...          ...                    ...  \n999640001/2020      0.0000      49.4732       0.0000                    0.0  \n999659209/2020      1.3426       0.0000       0.0000                    0.0  \n999662730/2020      0.0000       4.4841       8.6888                    0.0  \n999665462/2020      0.0000       0.0000       2.1835                    0.0  \n999666248/2020      9.5683       0.0000       0.0000                    0.0  \n\n[38478 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bygg_sum_0</th>\n      <th>hvete_sum_0</th>\n      <th>havre_sum_0</th>\n      <th>rug_og_rughvete_sum_0</th>\n      <th>bygg_sum_1</th>\n      <th>hvete_sum_1</th>\n      <th>havre_sum_1</th>\n      <th>rug_og_rughvete_sum_1</th>\n      <th>bygg_sum_2</th>\n      <th>hvete_sum_2</th>\n      <th>havre_sum_2</th>\n      <th>rug_og_rughvete_sum_2</th>\n      <th>bygg_sum_3</th>\n      <th>hvete_sum_3</th>\n      <th>havre_sum_3</th>\n      <th>rug_og_rughvete_sum_3</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>1.3687</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2050</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.0620</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2445</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>2.9200</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>4.7596</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>6.4999</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>11.7227</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.8870</td>\n      <td>0.6015</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.4844</td>\n      <td>0.2770</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>2.2717</td>\n      <td>0.4869</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.0643</td>\n      <td>2.5620</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>1.7688</td>\n      <td>0.4413</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>3.3676</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.7060</td>\n      <td>1.4768</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>2.2838</td>\n      <td>1.0750</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999640001/2020</th>\n      <td>14.6406</td>\n      <td>0.0000</td>\n      <td>4.8990</td>\n      <td>0.0</td>\n      <td>9.4914</td>\n      <td>33.1335</td>\n      <td>5.0059</td>\n      <td>0.0</td>\n      <td>8.4269</td>\n      <td>6.3109</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>49.4732</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999659209/2020</th>\n      <td>1.8102</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.1576</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.5396</td>\n      <td>0.0</td>\n      <td>1.3426</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999662730/2020</th>\n      <td>0.0000</td>\n      <td>2.9122</td>\n      <td>10.4515</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>4.7917</td>\n      <td>8.2873</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.8919</td>\n      <td>5.8078</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>4.4841</td>\n      <td>8.6888</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999665462/2020</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.1122</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.6108</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.1835</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999666248/2020</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>9.8484</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>8.5110</td>\n      <td>0.0</td>\n      <td>3.8498</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>9.5683</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>38478 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical = ku.get_historical_production(kornmo, deliveries.year.unique(), 4)\n",
    "historical = deliveries.merge(historical, how='left').fillna(0)\n",
    "historical[\"key\"] = historical.orgnr.astype(str) + \"/\" + historical.year.astype(str)\n",
    "historical = historical.drop(columns=deliveries.columns)\n",
    "historical = historical.drop_duplicates(subset='key')\n",
    "historical = historical.set_index(\"key\")\n",
    "#historical = filter_by_years(years, historical)\n",
    "\n",
    "historical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sunlight data...\n",
      "Number of loaded entries: 40616\n",
      "Loading daydegree5 data...\n",
      "Number of loaded entries: 40616\n",
      "Loading ground data...\n",
      "Number of loaded entries: 40616\n",
      "Loading weather data...\n",
      "Weather data entries loaded: 33003\n",
      "Merged 859 features of temp and precip data, 219 features of sunlight data, 216 features of daydegree data, 216 features of ground data to a total of 1504 features\n"
     ]
    },
    {
     "data": {
      "text/plain": "                growth_start_day  min_temp0  min_temp1  min_temp2  min_temp3  \\\nkey                                                                            \n811555762/2017          0.061905   0.491667   0.411667   0.421667   0.496667   \n811580082/2017          0.038095   0.505000   0.521667   0.560000   0.543333   \n811675792/2017          0.114286   0.485000   0.435000   0.503333   0.500000   \n811935662/2017          0.114286   0.491667   0.465000   0.473333   0.466667   \n812075322/2017          0.114286   0.458333   0.400000   0.440000   0.458333   \n...                          ...        ...        ...        ...        ...   \n997229789/2019          0.219048   0.456667   0.445000   0.423333   0.341667   \n997237269/2019          0.233333   0.418333   0.371667   0.486667   0.481667   \n997365747/2019          0.219048   0.405000   0.401667   0.388333   0.216667   \n997690877/2019          0.219048   0.488333   0.485000   0.433333   0.328333   \n998726581/2019          0.114286   0.451667   0.435000   0.575000   0.528333   \n\n                min_temp4  min_temp5  min_temp6  min_temp7  min_temp8  ...  \\\nkey                                                                    ...   \n811555762/2017   0.486667   0.448333   0.391667   0.361667   0.406667  ...   \n811580082/2017   0.526667   0.473333   0.413333   0.446667   0.560000  ...   \n811675792/2017   0.450000   0.430000   0.390000   0.300000   0.490000  ...   \n811935662/2017   0.438333   0.406667   0.370000   0.411667   0.488333  ...   \n812075322/2017   0.430000   0.410000   0.398333   0.300000   0.440000  ...   \n...                   ...        ...        ...        ...        ...  ...   \n997229789/2019   0.291667   0.281667   0.326667   0.396667   0.386667  ...   \n997237269/2019   0.415000   0.421667   0.453333   0.358333   0.320000  ...   \n997365747/2019   0.181667   0.143333   0.296667   0.383333   0.270000  ...   \n997690877/2019   0.250000   0.210000   0.313333   0.396667   0.268333  ...   \n998726581/2019   0.505000   0.506667   0.538333   0.508333   0.503333  ...   \n\n                 day_204  day_205  day_206   day_207   day_208   day_209  \\\nkey                                                                        \n811555762/2017  0.000000     0.00    0.000  0.000000  0.000000  0.000000   \n811580082/2017  0.285714     0.00    0.125  0.111111  0.000000  0.000000   \n811675792/2017  0.142857     0.25    0.125  0.111111  0.142857  0.111111   \n811935662/2017  0.142857     0.00    0.125  0.111111  0.285714  0.111111   \n812075322/2017  0.285714     0.50    0.125  0.222222  0.285714  0.222222   \n...                  ...      ...      ...       ...       ...       ...   \n997229789/2019       NaN      NaN      NaN       NaN       NaN       NaN   \n997237269/2019       NaN      NaN      NaN       NaN       NaN       NaN   \n997365747/2019  0.285714     0.50    0.125  0.111111  0.142857  0.111111   \n997690877/2019  0.285714     0.50    0.250  0.111111  0.142857  0.111111   \n998726581/2019  0.142857     0.25    0.125  0.111111  0.142857  0.111111   \n\n                 day_210   day_211   day_212   day_213  \nkey                                                     \n811555762/2017  0.000000  0.000000  0.000000  0.000000  \n811580082/2017  0.000000  0.111111  0.000000  0.222222  \n811675792/2017  0.285714  0.111111  0.000000  0.111111  \n811935662/2017  0.142857  0.111111  0.000000  0.000000  \n812075322/2017  0.285714  0.222222  0.000000  0.222222  \n...                  ...       ...       ...       ...  \n997229789/2019       NaN       NaN       NaN       NaN  \n997237269/2019       NaN       NaN       NaN       NaN  \n997365747/2019  0.142857  0.111111  0.111111  0.111111  \n997690877/2019  0.142857  0.111111  0.111111  0.222222  \n998726581/2019  0.285714  0.333333  0.333333  0.000000  \n\n[30873 rows x 1502 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>growth_start_day</th>\n      <th>min_temp0</th>\n      <th>min_temp1</th>\n      <th>min_temp2</th>\n      <th>min_temp3</th>\n      <th>min_temp4</th>\n      <th>min_temp5</th>\n      <th>min_temp6</th>\n      <th>min_temp7</th>\n      <th>min_temp8</th>\n      <th>...</th>\n      <th>day_204</th>\n      <th>day_205</th>\n      <th>day_206</th>\n      <th>day_207</th>\n      <th>day_208</th>\n      <th>day_209</th>\n      <th>day_210</th>\n      <th>day_211</th>\n      <th>day_212</th>\n      <th>day_213</th>\n    </tr>\n    <tr>\n      <th>key</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>811555762/2017</th>\n      <td>0.061905</td>\n      <td>0.491667</td>\n      <td>0.411667</td>\n      <td>0.421667</td>\n      <td>0.496667</td>\n      <td>0.486667</td>\n      <td>0.448333</td>\n      <td>0.391667</td>\n      <td>0.361667</td>\n      <td>0.406667</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>811580082/2017</th>\n      <td>0.038095</td>\n      <td>0.505000</td>\n      <td>0.521667</td>\n      <td>0.560000</td>\n      <td>0.543333</td>\n      <td>0.526667</td>\n      <td>0.473333</td>\n      <td>0.413333</td>\n      <td>0.446667</td>\n      <td>0.560000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>811675792/2017</th>\n      <td>0.114286</td>\n      <td>0.485000</td>\n      <td>0.435000</td>\n      <td>0.503333</td>\n      <td>0.500000</td>\n      <td>0.450000</td>\n      <td>0.430000</td>\n      <td>0.390000</td>\n      <td>0.300000</td>\n      <td>0.490000</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>811935662/2017</th>\n      <td>0.114286</td>\n      <td>0.491667</td>\n      <td>0.465000</td>\n      <td>0.473333</td>\n      <td>0.466667</td>\n      <td>0.438333</td>\n      <td>0.406667</td>\n      <td>0.370000</td>\n      <td>0.411667</td>\n      <td>0.488333</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.00</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>812075322/2017</th>\n      <td>0.114286</td>\n      <td>0.458333</td>\n      <td>0.400000</td>\n      <td>0.440000</td>\n      <td>0.458333</td>\n      <td>0.430000</td>\n      <td>0.410000</td>\n      <td>0.398333</td>\n      <td>0.300000</td>\n      <td>0.440000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.125</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.285714</td>\n      <td>0.222222</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>997229789/2019</th>\n      <td>0.219048</td>\n      <td>0.456667</td>\n      <td>0.445000</td>\n      <td>0.423333</td>\n      <td>0.341667</td>\n      <td>0.291667</td>\n      <td>0.281667</td>\n      <td>0.326667</td>\n      <td>0.396667</td>\n      <td>0.386667</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>997237269/2019</th>\n      <td>0.233333</td>\n      <td>0.418333</td>\n      <td>0.371667</td>\n      <td>0.486667</td>\n      <td>0.481667</td>\n      <td>0.415000</td>\n      <td>0.421667</td>\n      <td>0.453333</td>\n      <td>0.358333</td>\n      <td>0.320000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>997365747/2019</th>\n      <td>0.219048</td>\n      <td>0.405000</td>\n      <td>0.401667</td>\n      <td>0.388333</td>\n      <td>0.216667</td>\n      <td>0.181667</td>\n      <td>0.143333</td>\n      <td>0.296667</td>\n      <td>0.383333</td>\n      <td>0.270000</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n    </tr>\n    <tr>\n      <th>997690877/2019</th>\n      <td>0.219048</td>\n      <td>0.488333</td>\n      <td>0.485000</td>\n      <td>0.433333</td>\n      <td>0.328333</td>\n      <td>0.250000</td>\n      <td>0.210000</td>\n      <td>0.313333</td>\n      <td>0.396667</td>\n      <td>0.268333</td>\n      <td>...</td>\n      <td>0.285714</td>\n      <td>0.50</td>\n      <td>0.250</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.111111</td>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>998726581/2019</th>\n      <td>0.114286</td>\n      <td>0.451667</td>\n      <td>0.435000</td>\n      <td>0.575000</td>\n      <td>0.528333</td>\n      <td>0.505000</td>\n      <td>0.506667</td>\n      <td>0.538333</td>\n      <td>0.508333</td>\n      <td>0.503333</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.25</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.111111</td>\n      <td>0.285714</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>30873 rows × 1502 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunlight_data = get_interpolated_data(years, 'sunlight')\n",
    "daydegree5_data = get_interpolated_data(years, 'daydegree5').drop(columns=['longitude', 'latitude', 'elevation'])\n",
    "ground_data = get_proximity_data(years, 'ground')\n",
    "temp_and_precip_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "weather_data = temp_and_precip_data.merge(sunlight_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(daydegree5_data, how='left', on=['orgnr', 'year'])\n",
    "weather_data = weather_data.merge(ground_data, how='left', on=['orgnr', 'year'])\n",
    "\n",
    "print(f\"Merged {temp_and_precip_data.shape[1]} features of temp and precip data, {sunlight_data.shape[1]} features of sunlight data, {daydegree5_data.shape[1]} features of daydegree data, {ground_data.shape[1]} features of ground data to a total of {weather_data.shape[1]} features\")\n",
    "\n",
    "#weather_data = frost.get_as_aggregated(1).dropna().astype(float)\n",
    "\n",
    "weather_data[\"key\"] = weather_data.orgnr.astype(int).astype(str) + \"/\" + weather_data.year.astype(int).astype(str)\n",
    "weather_data.drop(columns=[\"year\", \"orgnr\"], inplace=True)\n",
    "weather_data = weather_data.drop_duplicates(subset=[\"key\"])\n",
    "weather_data = weather_data.set_index(\"key\")\n",
    "weather_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Combine dataset\n",
    "\n",
    "# sat_img_path = 'C:/'\n",
    "# from sentinel.storage import SentinelDataset\n",
    "# print(\"Reading sentinel_100x100_0.h5\")\n",
    "# ds0 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_0.h5\")\n",
    "# print(\"Reading sentinel_100x100_1.h5\")\n",
    "# ds1 = SentinelDataset(f\"{sat_img_path}/sentinel_100x100_1.h5\")\n",
    "# print(\"Combining both\")\n",
    "# SentinelDataset.combine_datasets([ds0, ds1], \"E:/combined_compressed.h5\", compression=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13597/13597 [00:06<00:00, 2127.79it/s]\n",
      "100%|██████████| 13582/13582 [00:00<00:00, 30725.13it/s]\n",
      "100%|██████████| 12876/12876 [00:13<00:00, 989.01it/s] \n",
      "100%|██████████| 3400/3400 [00:01<00:00, 2146.93it/s]\n",
      "100%|██████████| 3395/3395 [00:00<00:00, 28606.11it/s]\n",
      "100%|██████████| 3182/3182 [00:03<00:00, 990.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentinel.storage import SentinelDataset\n",
    "sat_img_path = 'E:/MasterThesisData/Satellite_Images'\n",
    "#sat_img_path = 'C:/'\n",
    "sd = SentinelDataset(f\"{sat_img_path}/combined_uncompressed.h5\")\n",
    "train, val = sd.to_iterator().split(rand_seed='abc')\n",
    "\n",
    "def add_historical(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" in historical.index.values:\n",
    "        h_data = historical.loc[f\"{orgnr}/{year}\"]\n",
    "        return {'historical': h_data.values }\n",
    "    else:\n",
    "        return []\n",
    "def add_weather(orgnr, year, data):\n",
    "    if f\"{orgnr}/{year}\" not in weather_data.index:\n",
    "        return []\n",
    "    wd = weather_data.loc[f\"{orgnr}/{year}\"]\n",
    "    # min_temps = [value for key, value in wd.items() if key.startswith(\"min_temp\")]\n",
    "    # mean_temps = [value for key, value in wd.items() if key.startswith(\"mean_temp\")]\n",
    "    # max_temps = [value for key, value in wd.items() if key.startswith(\"max_temp\")]\n",
    "    # total_rain = [value for key, value in wd.items() if key.startswith(\"total_rain\")]\n",
    "    # stacked = np.stack((min_temps, mean_temps, max_temps, total_rain), axis=1)\n",
    "\n",
    "    return { 'weather': wd.values }\n",
    "\n",
    "def add_grain_types(orgnr, year, data):\n",
    "    samples = deliveries.loc[[f\"{orgnr}/{year}\"]]\n",
    "\n",
    "    all_grains = []\n",
    "    for _, row in samples.iterrows():\n",
    "        sample = {}\n",
    "        if row.bygg: sample[\"type\"] = (1,0,0,0)\n",
    "        elif row.havre: sample[\"type\"] = (0,1,0,0)\n",
    "        elif row.rug_og_rughvete: sample[\"type\"] = (0,0,1,0)\n",
    "        elif row.hvete: sample[\"type\"] = (0,0,0,1)\n",
    "\n",
    "        sample[\"areal\"] = row[\"areal\"]\n",
    "        sample[\"lat\"] = row[\"lat\"]\n",
    "        sample[\"elevation\"] = row[\"elevation\"]\n",
    "        sample[\"yield\"] = row[\"yield\"]\n",
    "        sample['fulldyrket'] = row['fulldyrket']\n",
    "        sample['overflatedyrket'] = row['overflatedyrket']\n",
    "        sample['tilskudd_dyr'] = row['tilskudd_dyr']\n",
    "        all_grains.append(sample)\n",
    "\n",
    "    return all_grains\n",
    "\n",
    "train = train.with_data(add_historical, True)\\\n",
    "             .with_data(add_weather, True)\\\n",
    "             .with_data(add_grain_types, True)\n",
    "\n",
    "val = val.with_data(add_historical, True)\\\n",
    "         .with_data(add_weather, True)\\\n",
    "         .with_data(add_grain_types, True)\n",
    "\n",
    "#13597\n",
    "#13582\n",
    "#12876\n",
    "#3400\n",
    "#3395\n",
    "#3182"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 19003\n",
      "val samples: 4706\n"
     ]
    }
   ],
   "source": [
    "from mask.mask_dataset import MaskDataset\n",
    "from mask.utils import add_mask_as_channel, apply_mask_to_image_series\n",
    "\n",
    "mask_dataset_path = \"data/masks/nibio_disposed_properties_masks.h5\"\n",
    "mask_dataset = MaskDataset(mask_dataset_path)\n",
    "#print(mask_dataset.labels)\n",
    "\n",
    "mask_iterator = mask_dataset.get_iterator()\n",
    "mask_dict = {}\n",
    "for orgnr, year, mask in mask_iterator:\n",
    "    mask_dict[f'{orgnr}/{year}'] = mask\n",
    "\n",
    "def apply_mask(orgnr, year, imgs):\n",
    "    mask = mask_dict[f'{orgnr}/{year}']\n",
    "    return apply_mask_to_image_series(mask, imgs)\n",
    "\n",
    "train = train.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "val = val.filter(lambda orgnr, year, _,__: f\"{orgnr}/{year}\" in mask_dict)\n",
    "\n",
    "print(f\"train samples: {len(train)}\")\n",
    "print(f\"val samples: {len(val)}\")\n",
    "#19003\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented samples: 95015\n",
      "Validation samples: 4706\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.data.experimental import assert_cardinality\n",
    "from sentinel.transform import salt_n_pepper, rotate180, rotate90\n",
    "\n",
    "stride = 10\n",
    "def top_left(imgs):\n",
    "    return imgs[...,:-stride, :-stride,:]\n",
    "def top_right(imgs):\n",
    "    return imgs[...,:-stride, stride:,:]\n",
    "def bot_left(imgs):\n",
    "    return imgs[...,stride:, :-stride,:]\n",
    "def bot_right(imgs):\n",
    "    return imgs[...,stride:, stride:,:]\n",
    "def center(imgs):\n",
    "    s = stride//2\n",
    "    return imgs[...,s:-s, s:-s,:]\n",
    "\n",
    "def rotate_random(imgs):\n",
    "    angle = np.random.rand(30) * 6.28\n",
    "    return tfa.image.rotate(imgs, angle)\n",
    "\n",
    "augmented_dataset = train\\\n",
    "    .transform(apply_mask)\\\n",
    "    .transform(salt_n_pepper())\\\n",
    "    .augment([center, top_left, top_right, bot_left, bot_right], keep_original=False)\\\n",
    "    .transform(rotate_random)\n",
    "\n",
    "def apply_output(orgnr, year, img_source, data):\n",
    "    features = data[\"areal\"], *data[\"type\"]\n",
    "    output = data[\"yield\"]\n",
    "    weather = data[\"weather\"][1:]\n",
    "    return {\"cnn_input\": img_source[0:30], \"feature_input\": features, \"weather_input\": weather}, output\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    augmented_dataset.apply(apply_output).shuffled(),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(assert_cardinality(len(augmented_dataset)))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val.transform(apply_mask).transform(center).apply(apply_output),\n",
    "    output_types=({\"cnn_input\": tf.dtypes.float64, \"feature_input\": tf.dtypes.float64, \"weather_input\": tf.dtypes.float64}, tf.dtypes.float64),\n",
    ").apply(assert_cardinality(len(val)))\n",
    "\n",
    "print(f\"Augmented samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "#95015\n",
    "#4706"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 24/313 [=>............................] - ETA: 28:19 - loss: 0.1049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5080/1898569773.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[0mcnn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'./training/yield_hybrid/epoch_10.hdf5'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[1;31m# update the learning rate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 71\u001B[1;33m     cnn_history = cnn.fit(\n\u001B[0m\u001B[0;32m     72\u001B[0m         \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprefetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m         \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprefetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    952\u001B[0m       \u001B[1;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    953\u001B[0m       \u001B[1;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 954\u001B[1;33m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    955\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_created_variables\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    956\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "def CNN(input_dim, output_dim):\n",
    "    input_layer = layers.Input(shape=input_dim)\n",
    "    y = layers.Conv2D(16, (3, 3), activation=tf.nn.relu, padding='same')(input_layer)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding='same')(y)\n",
    "    y = layers.MaxPool2D((2, 2))(y)\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(output_dim, activation=tf.nn.relu)(y)\n",
    "\n",
    "    return models.Model(inputs=[input_layer], outputs=[y], name=\"SingleImageCNN\")\n",
    "\n",
    "file_path = \"./training/yield_hybrid/hybrid_yield_model.h5\"\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    file_path,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "callbacks = [callback, model_checkpoint]\n",
    "\n",
    "restart = False\n",
    "if restart:\n",
    "\n",
    "    scnn = CNN((90, 90, 12), 64)\n",
    "    #scnn.summary(line_length=130)\n",
    "    input_weather = layers.Input(shape=1501, name=\"weather_input\") #shape = 856 / 1501\n",
    "    t_wm = layers.Reshape((19, 79))(input_weather) # (4, 214) / (19, 79)\n",
    "    t_wm = layers.Permute((2, 1))(t_wm)\n",
    "    t_wm = layers.Conv1D(64, 50, activation=tf.nn.relu)(t_wm) # (64, 7, 7) / (64, 50)\n",
    "\n",
    "    input_cnn = layers.Input(shape=(30, 90, 90, 12), name=\"cnn_input\")\n",
    "\n",
    "    feature_input = layers.Input(shape=(5,), name=\"feature_input\")\n",
    "    feature_repeated = layers.RepeatVector(30)(feature_input)\n",
    "\n",
    "    cnn = layers.TimeDistributed(scnn)(input_cnn)\n",
    "    cnn = layers.Concatenate(axis=2)([cnn, feature_repeated, t_wm])\n",
    "    cnn = layers.GRU(128, return_sequences=False)(cnn)\n",
    "    cnn = layers.Flatten()(cnn)\n",
    "    cnn = layers.Dense(128, activation=tf.nn.relu)(cnn)\n",
    "    cnn = layers.Dense(1)(cnn)\n",
    "\n",
    "    cnn = models.Model(inputs=[input_weather, input_cnn, feature_input], outputs=cnn, name=\"CNN\")\n",
    "    #cnn.summary(line_length=130)\n",
    "\n",
    "    cnn.compile(optimizer=optimizers.Adam(), loss='mean_absolute_error')\n",
    "\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "else:\n",
    "    cnn = load_model('./training/yield_hybrid/epoch_10.hdf5')\n",
    "    # update the learning rate\n",
    "    cnn_history = cnn.fit(\n",
    "        train_dataset.take(10000).batch(32).prefetch(2),\n",
    "        validation_data=val_dataset.batch(32).prefetch(2),\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cnn = load_model('./training/yield_hybrid/epoch_10.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 628s 4s/step - loss: 0.1004\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.10043808072805405"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(val_dataset.batch(32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(history['loss'].tolist(), label=\"loss\")\n",
    "plt.plot(history['val_loss'].tolist(), label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Mean absolute error loss\")\n",
    "plt.savefig('logs/hybrid_more_features.svg', dpi=600)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}