{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from kornmo import KornmoDataset\n",
    "from frostdataset import FrostDataset\n",
    "from geodata import get_farmer_elevation\n",
    "from visualize import plot\n",
    "import kornmo_utils as ku\n",
    "from visualize import plot_history\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_by_years(years, data):\n",
    "    return data[data['year'].isin(years)]\n",
    "\n",
    "def get_interpolated_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/nn_interpolated/{weather_feature}/{weather_feature}_interpolated_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    # Drop columns containing 'Unnamed'\n",
    "    data.drop(columns=[col for col in data.columns if 'Unnamed' in col], inplace=True)\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year', 'longitude', 'latitude', 'elevation']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data\n",
    "\n",
    "def get_proximity_data(years, weather_feature):\n",
    "    data = pd.DataFrame()\n",
    "    print(f\"Loading {weather_feature} data...\")\n",
    "    for year in years:\n",
    "        tmp_df = pd.read_csv(f'../../kornmo-data-files/raw-data/weather-data/by_proximity/{weather_feature}/{weather_feature}_by_proximity_{year}-03-01_to_{year}-10-01.csv')\n",
    "        tmp_df.drop(columns=['ws_id'], inplace=True)\n",
    "        tmp_df.insert(0, 'year', year)\n",
    "        data = pd.concat([data, tmp_df])\n",
    "\n",
    "    return_data = ku.normalize(data.filter(regex='day_.*'))\n",
    "    columns_to_add = ['orgnr', 'year']\n",
    "    for i, col in enumerate(columns_to_add):\n",
    "        return_data.insert(i, col, data[col])\n",
    "\n",
    "\n",
    "    print(f\"Number of loaded entries: {return_data.shape[0]}\")\n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frost = FrostDataset()\n",
    "kornmo = KornmoDataset()\n",
    "\n",
    "years = [2017, 2018, 2019, 2020]\n",
    "\n",
    "# Grants and deliveries\n",
    "data = kornmo.get_deliveries().pipe(ku.split_farmers_on_type)\n",
    "data = filter_by_years(years, data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Temperature and Precipitation\n",
    "temp_and_precip_data = frost.get_as_aggregated(1, years=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.merge(temp_and_precip_data, on=['year', 'orgnr'])\n",
    "data = filter_by_years(years, data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lat, lon , elevation\n",
    "elevation_data = get_farmer_elevation()\n",
    "data = data.merge(elevation_data, on=['orgnr'])\n",
    "data = filter_by_years(years, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Legacy grants\n",
    "historical_data = ku.get_historical_production(kornmo, data.year.unique(), 4)\n",
    "data = data.merge(historical_data, on=['orgnr', 'year'])\n",
    "data = filter_by_years(years, data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "\n",
    "data['y'] = data['levert'] / data['areal']\n",
    "data.drop('levert', axis=1, inplace=True)\n",
    "\n",
    "data['y'] = ku.normalize(data['y'], 0, 1000)\n",
    "data['areal'] = ku.normalize(data['areal'])\n",
    "data['fulldyrket'] = ku.normalize(data['fulldyrket'])\n",
    "data['overflatedyrket'] = ku.normalize(data['overflatedyrket'])\n",
    "data['tilskudd_dyr'] = ku.normalize(data['tilskudd_dyr'])\n",
    "data['growth_start_day'] = ku.normalize(data['growth_start_day'])\n",
    "data['elevation'] = ku.normalize(data['elevation'])\n",
    "data['lat'] = ku.normalize(data['lat'])\n",
    "\n",
    "y_column = ['y']\n",
    "remove_from_training = ['orgnr', 'kommunenr', 'gaardsnummer', 'bruksnummer', 'festenummer', 'year'] + y_column\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(shuffle(data), test_size=0.2)\n",
    "val, test = train_test_split(val, test_size=0.2)\n",
    "\n",
    "train_x = train.drop(remove_from_training, axis=1).to_numpy()\n",
    "train_y = train[y_column].to_numpy()\n",
    "\n",
    "val_x = val.drop(remove_from_training, axis=1).to_numpy()\n",
    "val_y = val[y_column].to_numpy()\n",
    "\n",
    "print(f'Training dataset x: {train_x.shape}')\n",
    "print(f'Training dataset y: {train_y.shape}')\n",
    "print(f'Validation dataset x: {val_x.shape}')\n",
    "print(f'Validation dataset y : {val_y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dense_model import train_simple_dense\n",
    "logs_name = 'more_data'\n",
    "\n",
    "model, history = train_simple_dense(train_x, train_y, val_x, val_y)\n",
    "plot(model, val_x, val_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}