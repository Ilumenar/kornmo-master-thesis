{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sentinel.storage import SentinelDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "CLASSES = ['bygg', 'rug', 'rughvete', 'hvete', 'havre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "sd = SentinelDataset('E:/MasterThesisData/Satellite_Images/small_images_all.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "       planted          area  \\\n0         bygg  94540.480524   \n1         bygg  22778.560014   \n2         bygg   5072.924216   \n3         bygg  11611.972746   \n4        havre  10203.282317   \n...        ...           ...   \n404939    None  81170.744027   \n404940    None  47871.002364   \n404941    None  22108.550434   \n404942    None  65288.461984   \n404943    None  36594.376498   \n\n                                                 geometry  \\\n0       POLYGON ((301788.79090 6608202.23000, 301789.4...   \n1       POLYGON ((301588.81297 6607862.03284, 301582.7...   \n2       POLYGON ((301544.54510 6608141.21000, 301539.9...   \n3       POLYGON ((301285.90120 6608685.32060, 301285.7...   \n4       POLYGON ((281369.42428 6687420.41295, 281369.5...   \n...                                                   ...   \n404939  POLYGON ((292000.79988 6740131.57158, 291935.5...   \n404940  POLYGON ((292036.72990 6740255.23060, 292031.3...   \n404941  POLYGON ((326429.63114 7113387.26610, 326330.0...   \n404942  POLYGON ((326242.48690 7113421.74470, 326235.8...   \n404943  POLYGON ((326167.23194 7113891.42179, 326118.7...   \n\n                         key  \n0            8119356620/2019  \n1            8119356621/2019  \n2            8119356622/2019  \n3            8119356623/2019  \n4            8125305424/2019  \n...                      ...  \n404939  999315089404939/2017  \n404940  999315089404940/2017  \n404941  999552579404941/2017  \n404942  999552579404942/2017  \n404943  999552579404943/2017  \n\n[247060 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>planted</th>\n      <th>area</th>\n      <th>geometry</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bygg</td>\n      <td>94540.480524</td>\n      <td>POLYGON ((301788.79090 6608202.23000, 301789.4...</td>\n      <td>8119356620/2019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bygg</td>\n      <td>22778.560014</td>\n      <td>POLYGON ((301588.81297 6607862.03284, 301582.7...</td>\n      <td>8119356621/2019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bygg</td>\n      <td>5072.924216</td>\n      <td>POLYGON ((301544.54510 6608141.21000, 301539.9...</td>\n      <td>8119356622/2019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bygg</td>\n      <td>11611.972746</td>\n      <td>POLYGON ((301285.90120 6608685.32060, 301285.7...</td>\n      <td>8119356623/2019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>havre</td>\n      <td>10203.282317</td>\n      <td>POLYGON ((281369.42428 6687420.41295, 281369.5...</td>\n      <td>8125305424/2019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404939</th>\n      <td>None</td>\n      <td>81170.744027</td>\n      <td>POLYGON ((292000.79988 6740131.57158, 291935.5...</td>\n      <td>999315089404939/2017</td>\n    </tr>\n    <tr>\n      <th>404940</th>\n      <td>None</td>\n      <td>47871.002364</td>\n      <td>POLYGON ((292036.72990 6740255.23060, 292031.3...</td>\n      <td>999315089404940/2017</td>\n    </tr>\n    <tr>\n      <th>404941</th>\n      <td>None</td>\n      <td>22108.550434</td>\n      <td>POLYGON ((326429.63114 7113387.26610, 326330.0...</td>\n      <td>999552579404941/2017</td>\n    </tr>\n    <tr>\n      <th>404942</th>\n      <td>None</td>\n      <td>65288.461984</td>\n      <td>POLYGON ((326242.48690 7113421.74470, 326235.8...</td>\n      <td>999552579404942/2017</td>\n    </tr>\n    <tr>\n      <th>404943</th>\n      <td>None</td>\n      <td>36594.376498</td>\n      <td>POLYGON ((326167.23194 7113891.42179, 326118.7...</td>\n      <td>999552579404943/2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>247060 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_lookup = gpd.read_file('../../kornmo-data-files/raw-data/crop-classification-data/all_data.gpkg')\n",
    "labels_lookup[\"key\"] = labels_lookup.orgnr.astype(int).astype(str) + labels_lookup.index.astype(str) + \"/\" + labels_lookup.year.astype(int).astype(str)\n",
    "labels_lookup.drop(columns=[\"year\", \"orgnr\"], inplace=True)\n",
    "\n",
    "labels_lookup.drop(labels_lookup[labels_lookup['area'] < 1500].index, inplace = True)\n",
    "labels_lookup = labels_lookup.loc[labels_lookup['planted'] != 'erter']\n",
    "labels_lookup = labels_lookup.loc[labels_lookup['planted'] != 'oljefro']\n",
    "\n",
    "# labels_lookup = labels_lookup.set_index(\"key\")\n",
    "labels_lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bygg        76231\n",
      "havre       20512\n",
      "hvete       18102\n",
      "rug           816\n",
      "rughvete      517\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "       planted          area  \\\n0         bygg  94540.480524   \n1         bygg  22778.560014   \n2         bygg   5072.924216   \n3         bygg  11611.972746   \n4        havre  10203.282317   \n...        ...           ...   \n404939    None  81170.744027   \n404940    None  47871.002364   \n404941    None  22108.550434   \n404942    None  65288.461984   \n404943    None  36594.376498   \n\n                                                 geometry  \\\n0       POLYGON ((301788.79090 6608202.23000, 301789.4...   \n1       POLYGON ((301588.81297 6607862.03284, 301582.7...   \n2       POLYGON ((301544.54510 6608141.21000, 301539.9...   \n3       POLYGON ((301285.90120 6608685.32060, 301285.7...   \n4       POLYGON ((281369.42428 6687420.41295, 281369.5...   \n...                                                   ...   \n404939  POLYGON ((292000.79988 6740131.57158, 291935.5...   \n404940  POLYGON ((292036.72990 6740255.23060, 292031.3...   \n404941  POLYGON ((326429.63114 7113387.26610, 326330.0...   \n404942  POLYGON ((326242.48690 7113421.74470, 326235.8...   \n404943  POLYGON ((326167.23194 7113891.42179, 326118.7...   \n\n                         key  \n0            8119356620/2019  \n1            8119356621/2019  \n2            8119356622/2019  \n3            8119356623/2019  \n4            8125305424/2019  \n...                      ...  \n404939  999315089404939/2017  \n404940  999315089404940/2017  \n404941  999552579404941/2017  \n404942  999552579404942/2017  \n404943  999552579404943/2017  \n\n[247060 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>planted</th>\n      <th>area</th>\n      <th>geometry</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bygg</td>\n      <td>94540.480524</td>\n      <td>POLYGON ((301788.79090 6608202.23000, 301789.4...</td>\n      <td>8119356620/2019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bygg</td>\n      <td>22778.560014</td>\n      <td>POLYGON ((301588.81297 6607862.03284, 301582.7...</td>\n      <td>8119356621/2019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bygg</td>\n      <td>5072.924216</td>\n      <td>POLYGON ((301544.54510 6608141.21000, 301539.9...</td>\n      <td>8119356622/2019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bygg</td>\n      <td>11611.972746</td>\n      <td>POLYGON ((301285.90120 6608685.32060, 301285.7...</td>\n      <td>8119356623/2019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>havre</td>\n      <td>10203.282317</td>\n      <td>POLYGON ((281369.42428 6687420.41295, 281369.5...</td>\n      <td>8125305424/2019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404939</th>\n      <td>None</td>\n      <td>81170.744027</td>\n      <td>POLYGON ((292000.79988 6740131.57158, 291935.5...</td>\n      <td>999315089404939/2017</td>\n    </tr>\n    <tr>\n      <th>404940</th>\n      <td>None</td>\n      <td>47871.002364</td>\n      <td>POLYGON ((292036.72990 6740255.23060, 292031.3...</td>\n      <td>999315089404940/2017</td>\n    </tr>\n    <tr>\n      <th>404941</th>\n      <td>None</td>\n      <td>22108.550434</td>\n      <td>POLYGON ((326429.63114 7113387.26610, 326330.0...</td>\n      <td>999552579404941/2017</td>\n    </tr>\n    <tr>\n      <th>404942</th>\n      <td>None</td>\n      <td>65288.461984</td>\n      <td>POLYGON ((326242.48690 7113421.74470, 326235.8...</td>\n      <td>999552579404942/2017</td>\n    </tr>\n    <tr>\n      <th>404943</th>\n      <td>None</td>\n      <td>36594.376498</td>\n      <td>POLYGON ((326167.23194 7113891.42179, 326118.7...</td>\n      <td>999552579404943/2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>247060 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_keep = [f\"{int(label.split('/')[1])}/{int(label.split('/')[2])}\" for label in sd.labels]\n",
    "\n",
    "print(pd.Series(list(labels_lookup['planted'])).value_counts())\n",
    "labels_lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# def add_labels(orgnr, year, imgs):\n",
    "#     if f\"{orgnr}/{year}\" in unique:\n",
    "#         label = labels_lookup.loc[labels_lookup['key'] == f\"{orgnr}/{year}\"]['planted'].iloc[0]\n",
    "#         return {'class': label}\n",
    "\n",
    "\n",
    "all_images = sd.to_iterator().shuffled()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for img in all_images:\n",
    "#     print(img)\n",
    "#     if i > 10:\n",
    "#         break\n",
    "#     i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8034/15000 [03:15<02:49, 41.19it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 720. KiB for an array with shape (30, 16, 16, 12) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19364/1043491285.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;31m# img = tf.image.random_brightness(data[2][()], max_delta=0.5)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;31m# flipped = tf.image.flip_left_right(data[2][()])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mdata_x\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;34mf\"{int(data[0])}/{int(data[1])}\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0munique\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabels_lookup\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabels_lookup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'key'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34mf\"{int(data[0])}/{int(data[1])}\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'planted'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\OneDrive - Universitetet i Agder\\kornmo-master-thesis\\kornmo\\sentinel\\storage.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m         \u001B[0mimages\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_source\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mSentinelDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mINT_SCALE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mtransform\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__transformations\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 720. KiB for an array with shape (30, 16, 16, 12) and data type float64"
     ]
    }
   ],
   "source": [
    "unique = labels_lookup['key'].unique()\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "max_imgs = 15000\n",
    "i = 0\n",
    "for data in tqdm(all_images, total=max_imgs):\n",
    "    # img = tf.image.random_brightness(data[2][()], max_delta=0.5)\n",
    "    # flipped = tf.image.flip_left_right(data[2][()])\n",
    "    data_x.append(data[2][()])\n",
    "    if f\"{int(data[0])}/{int(data[1])}\" in unique:\n",
    "        label = labels_lookup.loc[labels_lookup['key'] == f\"{int(data[0])}/{int(data[1])}\"]['planted'].iloc[0]\n",
    "        data_y.append(label)\n",
    "    else:\n",
    "        data_y.append(None)\n",
    "    if i >= max_imgs - 1:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#print(np.array(data_x).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# labels = labels_lookup['planted']\n",
    "#\n",
    "# data_x = []\n",
    "# data_y = []\n",
    "# for i, label in tqdm(enumerate(labels_to_keep), total=len(labels_to_keep)):\n",
    "#     data_x.append(label)\n",
    "#     data_y.append(labels.iloc[i])\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_x, data_y, test_size=0.3, random_state=42)\n",
    "del data_x, data_y\n",
    "print(f'x_train: {len(x_train)}')\n",
    "print(f'x_val: {len(x_val)}')\n",
    "print(f'y_train: {len(y_train)}')\n",
    "print(f'y_val: {len(y_val)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BAG_COUNT = 100\n",
    "VAL_BAG_COUNT = 100\n",
    "BAG_SIZE = 7\n",
    "PLOT_SIZE = 3\n",
    "\n",
    "(BAG_COUNT + VAL_BAG_COUNT) * BAG_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n",
    "    bags = []\n",
    "    bag_labels = []\n",
    "\n",
    "    # input_data = np.divide(input_data, 255.0)\n",
    "\n",
    "    count = 0\n",
    "    for _ in tqdm(range(bag_count), desc=f'Creating bag for {positive_class}'):\n",
    "        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n",
    "        instances_data = input_data[index]\n",
    "        instances_labels = input_labels[index]\n",
    "\n",
    "        bag_label = 0\n",
    "\n",
    "        if positive_class in instances_labels:\n",
    "            bag_label = 1\n",
    "            count += 1\n",
    "\n",
    "        bags.append(instances_data)\n",
    "        bag_labels.append(np.array([bag_label]))\n",
    "\n",
    "    print(f\"Positive bags: {count}\")\n",
    "    print(f\"Negative bags: {bag_count - count}\")\n",
    "    # return list(np.swapaxes(bags, 0, 1)), np.array(bag_labels)\n",
    "    return list(np.swapaxes(bags, 0, 1)), np.array(bag_labels)\n",
    "\n",
    "\n",
    "train_data, train_labels = create_bags(np.array(x_train), np.array(y_train), 'rug', BAG_COUNT, BAG_SIZE)\n",
    "#del x_train, y_train\n",
    "val_data, val_labels = create_bags(np.array(x_val), np.array(y_val), 'rug', VAL_BAG_COUNT, BAG_SIZE)\n",
    "#del x_val, y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MILAttentionLayer(layers.Layer):\n",
    "\n",
    "    def  __init__(\n",
    "        self,\n",
    "        weight_params_dim,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        use_gated=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        super(MILAttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.weight_params_dim = weight_params_dim\n",
    "        self.use_gated = use_gated\n",
    "\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "        self.v_init = self.kernel_initializer\n",
    "        self.w_init = self.kernel_initializer\n",
    "        self.u_init = self.kernel_initializer\n",
    "\n",
    "        self.v_regularizer = self.kernel_regularizer\n",
    "        self.w_regularizer = self.kernel_regularizer\n",
    "        self.u_regularizer = self.kernel_regularizer\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MILAttentionLayer, self).get_config()\n",
    "        config.update({\"weight_params_dim\": self.weight_params_dim})\n",
    "        config.update({\"use_gated\": self.use_gated})\n",
    "        config.update({\"kernel_initializer\": self.kernel_initializer})\n",
    "        config.update({\"kernel_regularizer\": self.kernel_regularizer})\n",
    "\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # Input shape.\n",
    "        # List of 2D tensors with shape: (batch_size, input_dim).\n",
    "        input_dim = 48\n",
    "\n",
    "        self.v_weight_params = self.add_weight(\n",
    "            shape=(input_dim, self.weight_params_dim),\n",
    "            initializer=self.v_init,\n",
    "            name=\"v\",\n",
    "            regularizer=self.v_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_weight_params = self.add_weight(\n",
    "            shape=(self.weight_params_dim, 1),\n",
    "            initializer=self.w_init,\n",
    "            name=\"w\",\n",
    "            regularizer=self.w_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        if self.use_gated:\n",
    "            self.u_weight_params = self.add_weight(\n",
    "                shape=(input_dim, self.weight_params_dim),\n",
    "                initializer=self.u_init,\n",
    "                name=\"u\",\n",
    "                regularizer=self.u_regularizer,\n",
    "                trainable=True,\n",
    "            )\n",
    "        else:\n",
    "            self.u_weight_params = None\n",
    "\n",
    "        self.input_built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # Assigning variables from the number of inputs.\n",
    "        instances = [self.compute_attention_scores(instance) for instance in inputs]\n",
    "\n",
    "        # Apply softmax over instances such that the output summation is equal to 1.\n",
    "        alpha = tf.math.softmax(instances, axis=0)\n",
    "\n",
    "        return [alpha[i] for i in range(alpha.shape[0])]\n",
    "\n",
    "    def compute_attention_scores(self, instance):\n",
    "\n",
    "        # Reserve in-case \"gated mechanism\" used.\n",
    "        original_instance = instance\n",
    "\n",
    "        # tanh(v*h_k^T)\n",
    "        instance = tf.math.tanh(tf.tensordot(instance, self.v_weight_params, axes=1))\n",
    "\n",
    "        # for learning non-linear relations efficiently.\n",
    "        if self.use_gated:\n",
    "\n",
    "            instance = instance * tf.math.sigmoid(\n",
    "                tf.tensordot(original_instance, self.u_weight_params, axes=1)\n",
    "            )\n",
    "\n",
    "        # w^T*(tanh(v*h_k^T)) / w^T*(tanh(v*h_k^T)*sigmoid(u*h_k^T))\n",
    "        return tf.tensordot(instance, self.w_weight_params, axes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(instance_shape):\n",
    "\n",
    "    # Extract features from inputs.\n",
    "    inputs, embeddings = [], []\n",
    "    shared_dense_layer_1 = layers.Dense(96, activation=\"relu\")\n",
    "    dropout_layer = layers.Dropout(0.6)\n",
    "    shared_dense_layer_2 = layers.Dense(48, activation=\"relu\")\n",
    "    for _ in range(BAG_SIZE):\n",
    "        inp = layers.Input(instance_shape)\n",
    "        flatten = layers.Flatten()(inp)\n",
    "        dense_1 = shared_dense_layer_1(flatten)\n",
    "        dropout = dropout_layer(dense_1)\n",
    "        dense_2 = shared_dense_layer_2(dropout)\n",
    "        inputs.append(inp)\n",
    "        embeddings.append(dense_2)\n",
    "\n",
    "    # Invoke the attention layer.\n",
    "    alpha = MILAttentionLayer(weight_params_dim=256, kernel_regularizer=keras.regularizers.l2(0.001), use_gated=True, name=\"alpha\")\n",
    "    alpha = alpha(embeddings)\n",
    "\n",
    "    # Multiply attention weights with the input layers.\n",
    "    multiply_layers = [\n",
    "        layers.multiply([alpha[i], embeddings[i]]) for i in range(len(alpha))\n",
    "    ]\n",
    "\n",
    "    # Concatenate layers.\n",
    "    concat = layers.concatenate(multiply_layers, axis=1)\n",
    "\n",
    "    # Classification output node.\n",
    "    output = layers.Dense(2, activation=\"softmax\")(concat)\n",
    "\n",
    "    return keras.Model(inputs, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_class_weights(labels):\n",
    "\n",
    "    # Count number of postive and negative bags.\n",
    "    negative_count = len(np.where(labels == 0)[0])\n",
    "    positive_count = len(np.where(labels == 1)[0])\n",
    "    total_count = negative_count + positive_count\n",
    "\n",
    "    # Build class weight dictionary.\n",
    "    return {\n",
    "        0: (1 / negative_count) * (total_count / 2),\n",
    "        1: (1 / positive_count) * (total_count / 2),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def train(train_data, train_labels, val_data, val_labels, model):\n",
    "\n",
    "    # Take the file name from the wrapper.\n",
    "    file_path = \"../src/grain_classification/training/mil/mil_model.h5\"\n",
    "\n",
    "    # Initialize model checkpoint callback.\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        file_path,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=100, mode=\"min\", restore_best_weights=True)\n",
    "    # lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        validation_data=(val_data, val_labels),\n",
    "        epochs=150,\n",
    "        class_weight=compute_class_weights(train_labels),\n",
    "        batch_size=1,\n",
    "        callbacks=[model_checkpoint, early_stopping],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # model.load_weights(file_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#instance_shape = train_data[0][0].shape\n",
    "model = create_model((30, 16, 16, 12))\n",
    "# tf.keras.models.save_model(model, 'MIL_model.h5')\n",
    "#print(model2.summary())\n",
    "\n",
    "trained_model = train(train_data, train_labels, val_data, val_labels, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=trained_model.history.history['accuracy']\n",
    "val_acc=trained_model.history.history['val_accuracy']\n",
    "loss=trained_model.history.history['loss']\n",
    "val_loss=trained_model.history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Train_loss')\n",
    "plt.plot(val_loss, label='Val_loss')\n",
    "plt.plot(val_acc, label='Val_acc')\n",
    "plt.plot(acc, label='Train_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.evaluate(val_data, val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.utils import to_rgb\n",
    "\n",
    "def get_labels_and_bags(data, labels, bag_class, predictions=None):\n",
    "    if bag_class == \"positive\":\n",
    "        if predictions is not None:\n",
    "            print(1)\n",
    "            labels = np.where(predictions.argmax(1) == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "            return labels, bags\n",
    "        else:\n",
    "            print(2)\n",
    "            labels = np.where(labels == 1)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "            return labels, bags\n",
    "    elif bag_class == \"negative\":\n",
    "        if predictions is not None:\n",
    "            print(3)\n",
    "            labels = np.where(predictions.argmax(1) == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "            return labels, bags\n",
    "        else:\n",
    "            print(4)\n",
    "            labels = np.where(labels == 0)[0]\n",
    "            bags = np.array(data)[:, labels[0:PLOT_SIZE]]\n",
    "            return labels, bags\n",
    "\n",
    "def plot(data, labels, bag_class, predictions=None, attention_weights=None):\n",
    "\n",
    "    labels, bags = get_labels_and_bags(data, labels, bag_class, predictions=predictions)\n",
    "    labels = np.array(labels).reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"The bag class label is {bag_class}\")\n",
    "    for i in range(PLOT_SIZE):\n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        print(f\"Bag number: {labels[i]}\")\n",
    "        for j in range(BAG_SIZE):\n",
    "            image = bags[j][i]\n",
    "            figure.add_subplot(1, BAG_SIZE, j + 1)\n",
    "            plt.grid(False)\n",
    "            if attention_weights is not None:\n",
    "                plt.title(np.around(attention_weights[labels[i]][j], 2))\n",
    "\n",
    "            plt.imshow(to_rgb(image[15]))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Plot some of validation data bags per class.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(data, labels, trained_models):\n",
    "\n",
    "    # Collect info per model.\n",
    "    models_predictions = []\n",
    "    models_attention_weights = []\n",
    "    models_losses = []\n",
    "    models_accuracies = []\n",
    "\n",
    "    for model in trained_models:\n",
    "\n",
    "        # Predict output classes on data.\n",
    "        predictions = model.predict(data)\n",
    "        models_predictions.append(predictions)\n",
    "\n",
    "        # Create intermediate model to get MIL attention layer weights.\n",
    "        intermediate_model = keras.Model(model.input, model.get_layer(\"alpha\").output)\n",
    "\n",
    "        # Predict MIL attention layer weights.\n",
    "        intermediate_predictions = intermediate_model.predict(data)\n",
    "\n",
    "        attention_weights = np.squeeze(np.swapaxes(intermediate_predictions, 1, 0))\n",
    "        models_attention_weights.append(attention_weights)\n",
    "\n",
    "        loss, accuracy = model.evaluate(data, labels, verbose=0)\n",
    "        models_losses.append(loss)\n",
    "        models_accuracies.append(accuracy)\n",
    "\n",
    "    print(\n",
    "        f\"The average loss and accuracy are {np.sum(models_losses, axis=0):.2f}\"\n",
    "        f\" and {100 * np.sum(models_accuracies, axis=0):.2f} % resp.\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        np.sum(models_predictions, axis=0),\n",
    "        np.sum(models_attention_weights, axis=0),\n",
    "    )\n",
    "\n",
    "\n",
    "# Evaluate and predict classes and attention scores on validation data.\n",
    "class_predictions, attention_params = predict(val_data, val_labels, [model])\n",
    "\n",
    "# Plot some results from our validation data.\n",
    "plot(\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    \"positive\",\n",
    "    predictions=class_predictions,\n",
    "    attention_weights=attention_params,\n",
    ")\n",
    "plot(\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    \"negative\",\n",
    "    predictions=class_predictions,\n",
    "    attention_weights=attention_params,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}